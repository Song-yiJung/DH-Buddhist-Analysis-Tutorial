{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYrVOOcva8XUuQi22YvOMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-yiJung/DH-Buddhist-Analysis-Tutorial/blob/main/5_%ED%95%9C%EB%AC%B8%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%A1%9C_TF_IDF%EB%AA%A8%EB%8D%B8_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 핵심 단어를 찾아내는 TF-IDF의 원리와 실습\n",
        "\n",
        "## 1. TF-IDF란 무엇인가?\n",
        "\n",
        "4번 노트를 통하여 BoW를 통해 문서에 어떤 단어가 몇 번 등장하는지 세어보았다. 하지만 \"그리고\", \"그러나\", \"그는\" 처럼 자주 등장하지만 별 의미 없는 단어들도 높은 점수를 받는 문제가 있었다.\n",
        "\n",
        "TF-IDF는 이러한 문제를 해결하기 위해 등장한, 보다 정교한 텍스트 표현 방법이다. 단순히 단어의 빈도수만 보는 것이 아니라, **\"이 문서에서 이 단어가 얼마나 중요한가?\"**를 가중치로 표현한다.\n",
        "\n",
        "* 핵심 아이디어: 한 문서 안에서 자주 등장할수록(TF), 그리고 전체 문서들 중 특정 문서에만 집중적으로 등장할수록(IDF) 그 단어는 해당 문서를 대표하는 중요한 단어이다.\n",
        "\n",
        "이 중요도를 계산하기 위해 TF와 IDF라는 두 가지 지표를 사용합니다.\n",
        "\n",
        "* TF (Term Frequency - 단어 빈도): 특정 문서 내에서 특정 단어가 얼마나 자주 등장하는지를 나타내는 값. 이것은 우리가 BoW에서 했던 것과 동일하다.\n",
        "\n",
        " * (예: A라는 문서에 '훈민정음'이 10번 나오면, '훈민정음'의 TF는 10)\n",
        "\n",
        "\n",
        "* IDF (Inverse Document Frequency - 역문서 빈도): 특정 단어가 전체 문서들에서 얼마나 희귀하게 등장하는지를 나타내는 값. 이것이 TF-IDF의 핵심이다.\n",
        "\n",
        " * 많은 문서에 공통적으로 등장하는 단어(예: '그리고', '우리나라')는 IDF 값이 낮아진다 (중요도 하락).\n",
        " * 반대로, 특정 몇 개의 문서에만 등장하는 희귀한 단어(예: '코사인 유사도', '훈민정음')는 IDF 값이 높아진다 (중요도 상승).\n",
        "\n",
        "최종적으로 TF-IDF 값은 이 두 값을 곱해서 계산합니다: TF-IDF = TF * IDF"
      ],
      "metadata": {
        "id": "ThITWHG2kTYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. TF-IDF의 기원: 누가, 언제, 왜?\n",
        "\n",
        "* 누가/언제: TF-IDF의 핵심 개념인 IDF는 영국 케임브리지 대학의 컴퓨터 과학자 **캐런 스팍 존스(Karen Spärck Jones)**가 1972년에 발표한 논문에서 처음 소개했다. 그녀는 정보 검색 분야의 선구적인 여성 과학자였다. 이후 제라드 솔튼(Gerard Salton) 등이 이 아이디어를 발전시켜 현재의 TF-IDF 가중치 기법을 널리 알렸다.\n",
        "\n",
        "* 왜: BoW와 마찬가지로 정보 검색(Information Retrieval) 성능을 향상시키기 위해 개발되었다.\n",
        "\n",
        " 사용자가 '머신러닝'을 검색했을 때, '머신러닝'이라는 단어가 단순히 몇 번 포함된 문서보다, '머신러닝'이라는 단어의 TF-IDF 값이 높은, 즉 '머신러닝'을 핵심 주제로 다루는 전문적인 문서를 검색 결과 상단에 보여주기 위해서였다."
      ],
      "metadata": {
        "id": "uIG47Rv6lJEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 디지털 인문학에서의 활용\n",
        "TF-IDF는 문서의 핵심 키워드를 자동으로 추출하는 데 매우 강력한 성능을 보이기 때문에, 디지털 인문학 연구에서 광범위하게 활용된다.\n",
        "\n",
        "* 어디서/어떻게:\n",
        "\n",
        " * 역사 문헌 분석: 특정 시기(예: 조선왕조실록의 특정 왕 재위 기간)의 문헌들에서 TF-IDF 값이 높은 단어들을 추출하여, 해당 시기의 주요 정치·사회적 이슈나 사건을 객관적으로 파악할 수 있다. (예: 특정 시기에 '倭(왜)'나 '女眞(여진)'의 TF-IDF가 높다면, 당시 대외 관계가 중요한 이슈였음을 시사)\n",
        "\n",
        " * 문학 작품 비교 분석: 여러 작가의 작품집에서 각각 TF-IDF를 추출하여, 각 작가가 즐겨 사용하는 특징적인 어휘나 주제 의식을 비교 분석할 수 있다.\n",
        "\n",
        " * 고문서 자동 분류 및 요약: 각 고문서의 TF-IDF 상위 키워드들을 통해 해당 문서가 '외교', '농업', '법률' 중 어떤 주제에 속하는지 자동으로 분류하거나, 핵심 내용을 요약하는 데 활용할 수 있다."
      ],
      "metadata": {
        "id": "ZkEtt4XAlV__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. 파이썬 실습 코드\n",
        "\n",
        "scikit-learn의 TfidfVectorizer를 사용하면 매우 쉽게 TF-IDF 모델을 만들 수 있다. BoW를 만들었던 CountVectorizer와 사용법이 거의 동일하다.\n",
        "\n",
        "한글 텍스트를 예시로 원리를 먼저 파악해본다."
      ],
      "metadata": {
        "id": "EBTlRBy6lkjG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZSt1A3jukJrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf48b02-b339-488f-96d3-15ea7e85820b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF 가중치 행렬:\n",
            "         경제       구조가       다룬다        대한       문서는      문서이다      문자이다  \\\n",
            "0  0.000000  0.000000  0.000000  0.403016  0.306504  0.306504  0.403016   \n",
            "1  0.614922  0.307461  0.307461  0.000000  0.233832  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.276265  0.000000   \n",
            "\n",
            "       사용법을      설명하는       시대의  ...       위대한       정책을        조선      중요하다  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.403016  0.000000  0.000000  0.000000   \n",
            "1  0.000000  0.000000  0.307461  ...  0.000000  0.307461  0.307461  0.307461   \n",
            "2  0.363255  0.363255  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "        중요한        창제      해례본은      훈민정음     훈민정음에     훈민정음은  \n",
            "0  0.000000  0.000000  0.000000  0.000000  0.403016  0.403016  \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2  0.363255  0.363255  0.363255  0.363255  0.000000  0.000000  \n",
            "\n",
            "[3 rows x 21 columns]\n",
            "TF-IDF 가중치 행렬:\n",
            "         경제       구조가       다룬다        대한       문서는      문서이다      문자이다  \\\n",
            "0  0.000000  0.000000  0.000000  0.403016  0.306504  0.306504  0.403016   \n",
            "1  0.614922  0.307461  0.307461  0.000000  0.233832  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.276265  0.000000   \n",
            "\n",
            "       사용법을      설명하는       시대의  ...       위대한       정책을        조선      중요하다  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.403016  0.000000  0.000000  0.000000   \n",
            "1  0.000000  0.000000  0.307461  ...  0.000000  0.307461  0.307461  0.307461   \n",
            "2  0.363255  0.363255  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "        중요한        창제      해례본은      훈민정음     훈민정음에     훈민정음은  \n",
            "0  0.000000  0.000000  0.000000  0.000000  0.403016  0.403016  \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2  0.363255  0.363255  0.363255  0.363255  0.000000  0.000000  \n",
            "\n",
            "[3 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd # 결과를 보기 좋게 표로 만들기 위해 pandas를 사용합니다.\n",
        "\n",
        "# 비교할 예제 문서 3개\n",
        "documents = [\n",
        "    '이 문서는 훈민정음에 대한 문서이다. 훈민정음은 위대한 문자이다.', # 문서 1\n",
        "    '이 문서는 조선 시대의 경제 정책을 다룬다. 경제 구조가 중요하다.',  # 문서 2\n",
        "    '훈민정음 해례본은 창제 원리와 사용법을 설명하는 중요한 문서이다.'   # 문서 3\n",
        "]\n",
        "\n",
        "# 1. TF-IDF 벡터화 도구 생성\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 2. 문서를 학습(fit)하고 TF-IDF 행렬로 변환(transform)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# 3. 결과 확인\n",
        "# 생성된 어휘 사전(단어 목록) 확인\n",
        "vocab = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# 결과를 보기 쉽게 pandas DataFrame으로 변환\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab)\n",
        "print(\"TF-IDF 가중치 행렬:\")\n",
        "print(df_tfidf)\n",
        "# 비교할 예제 문서 3개\n",
        "documents = [\n",
        "    '이 문서는 훈민정음에 대한 문서이다. 훈민정음은 위대한 문자이다.', # 문서 1\n",
        "    '이 문서는 조선 시대의 경제 정책을 다룬다. 경제 구조가 중요하다.',  # 문서 2\n",
        "    '훈민정음 해례본은 창제 원리와 사용법을 설명하는 중요한 문서이다.'   # 문서 3\n",
        "]\n",
        "\n",
        "# 1. TF-IDF 벡터화 도구 생성\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 2. 문서를 학습(fit)하고 TF-IDF 행렬로 변환(transform)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# 3. 결과 확인\n",
        "# 생성된 어휘 사전(단어 목록) 확인\n",
        "vocab = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# 결과를 보기 쉽게 pandas DataFrame으로 변환\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab)\n",
        "print(\"TF-IDF 가중치 행렬:\")\n",
        "print(df_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 TF-IDF 가중치 행렬(표) 완벽하게 이해하기\n",
        "위의 코드 결과는 컴퓨터가 각 문서에서 어떤 단어가 중요한지를 분석하여 **'단어별 중요도 점수'**를 매겨놓은 성적표라고 생각하면 된다.\n",
        "\n",
        "\n",
        "### 1. 행(Row)의 의미: 0, 1, 2는 무엇인가?\n",
        "\n",
        "가장 왼쪽에 있는 숫자 0, 1, 2는 우리가 처음에 컴퓨터에 입력했던 documents 리스트의 문서 번호를 가리킨다.\n",
        "\n",
        "* 0 ➡️ 문서 1: '이 문서는 훈민정음에 대한 문서이다. 훈민정음은 위대한 문자이다.'\n",
        "* 1 ➡️ 문서 2: '이 문서는 조선 시대의 경제 정책을 다룬다. 경제 구조가 중요하다.'\n",
        "* 2 ➡️ 문서 3: '훈민정음 해례본은 창제 원리와 사용법을 설명하는 중요한 문서이다.'\n",
        "\n",
        "즉, 코드 결과의 각 가로 한 줄은 우리 예제의 문서 하나에 대한 분석 결과이다.\n",
        "\n",
        "### 2. 열(Column)의 의미: '경제', '훈민정음은' 등은 무엇인가?\n",
        "* 코드 결과의 맨 위쪽에 있는 '경제', '구조가', '다룬다', ... '훈민정음은' 등은 3개 문서에 등장한 모든 단어를 모아 만든 **'어휘 사전'**이다. 즉, 표의 각 세로 한 줄은 특정 단어 하나를 의미한다.\n",
        "\n",
        "* 이 부분은 TfidfVectorizer가 어떻게 단어를 인식하고 목록(어휘 사전)을 만드는지, 그 **'작동 원리'**와 직접적으로 관련이 있다.\n",
        "\n",
        "* 어휘 사전은 **TfidfVectorizer**가 정해진 규칙에 따라 모든 문서에서 단어를 추출하고 정리하여 자동으로 만들어 낸 결과이다. 해당 과정을 **어휘 사전이 만들어지는 4단계 과정**으로 별도로 설명문을 기술하였다. 이해가 필요하다면 해당 설명문을 참고하면 된다.\n",
        "\n",
        "### 3. 값(Value)의 의미: 0.614922와 같은 소수점 숫자는 무엇인가?\n",
        "각 칸의 숫자는 해당 문서(행)에서 해당 단어(열)가 얼마나 중요한지를 나타내는 TF-IDF 점수이다.\n",
        "\n",
        "* 숫자가 0.0 이면: 해당 문서에 그 단어가 전혀 등장하지 않는다는 의미이다.\n",
        "* 숫자가 높을수록: 해당 단어가 그 문서의 주제를 나타내는 매우 중요한 핵심 키워드라는 의미이다. (즉, 그 문서에서는 자주 나오고(TF↑), 다른 문서에서는 잘 안 나오는(IDF↑) 단어)\n",
        "* 숫자가 낮지만 0이 아니면: 단어가 문서에 등장하긴 하지만, 다른 문서에도 흔하게 등장하여 핵심 키워드까지는 아니라는 의미이다.\n"
      ],
      "metadata": {
        "id": "erTXbT3Tls8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ '어휘 사전(표의 열)'이 만들어지는 4단계 과정\n",
        "\n",
        "컴퓨터가 어떻게 '경제', '구조가', ..., '훈민정음은' 이라는 최종 목록을 만들었는지 살펴 본다.\n",
        "\n",
        "#### 1단계: 🔍 수집 (Collection)\n",
        "먼저, TfidfVectorizer는 우리가 제공한 documents 리스트에 있는 모든 문장을 훑어본다.\n",
        "\n",
        "* '이 문서는 훈민정음에 대한 문서이다. 훈민정음은 위대한 문자이다.'\n",
        "* '이 문서는 조선 시대의 경제 정책을 다룬다. 경제 구조가 중요하다.'\n",
        "* '훈민정음 해례본은 창제 원리와 사용법을 설명하는 중요한 문서이다.'\n",
        "\n",
        "#### 2단계: ✂️ 분해 및 정제 (Tokenization & Cleaning)\n",
        "그 다음, 수집한 문장들을 정해진 규칙에 따라 단어 단위로 자르고 깨끗하게 다듬는다. TfidfVectorizer의 기본 규칙은 다음과 같다.\n",
        "\n",
        "* 규칙 1 (공백 기준 분리): 가장 먼저 띄어쓰기를 기준으로 단어를 나눈다.\n",
        "\n",
        "  * '이 문서는 훈민정음에 대한 문서이다.' ➡️ ['이', '문서는', '훈민정음에', '대한', '문서이다.']\n",
        "\n",
        "* 규칙 2 (구두점 등 제거): 문장 부호(마침표, 쉼표 등)를 제거한다.\n",
        "\n",
        "  * ['이', '문서는', '훈민정음에', '대한', '문서이다.'] ➡️ ['이', '문서는', '훈민정음에', '대한', '문서이다']\n",
        "\n",
        "* 규칙 3 (두 글자 이상 단어만 인정): 기본 설정에서는 의미 없는 한 글자 단어(예: '이', '그' 등)는 보통 제외한다.\n",
        "\n",
        "* 규칙 4 (가장 중요!): 조사를 분리하지 않음.\n",
        "\n",
        "  * TfidfVectorizer는 한국어의 문법 구조를 모른다. 따라서 훈민정음이라는 명사와 은/는, 에 와 같은 조사를 분리하지 못한다. 그 결과, 컴퓨터에게는 훈민정음, 훈민정음에, 훈민정음은 이 세 단어가 모두 철자가 다른, 완전히 별개의 단어로 인식된다.\n",
        "  * '문서'와 '문서는', '경제'와 '경제가'도 서로 다른 단어로 취급된다. 이 과정을 모든 문서에 적용하면 다음과 같은 단어 조각들이 나온다.\n",
        "\n",
        "  * ['문서는', '훈민정음에', '대한', '문서이다', '훈민정음은', '위대한', '문자이다', '문서는', '조선', '시대의', '경제', ...]\n",
        "\n",
        "* 3단계: 📋 목록화 및 중복 제거 (Listing & Deduplication)\n",
        "\n",
        "  * 위에서 얻은 모든 단어 조각들을 하나의 큰 목록에 모은 뒤, 중복되는 단어들을 모두 제거하여 유일한 단어 목록을 만든다.\n",
        "\n",
        "* 4단계: 🔤 정렬 (Sorting)\n",
        "\n",
        "  * 마지막으로, 중복이 제거된 유일한 단어 목록을 **가나다순(사전순)**으로 정렬한다.\n",
        "\n",
        "  * 이렇게 해서 최종적으로 우리가 본 표의 열, 즉 '어휘 사전'이 완성되는 것이다.\n",
        "\n",
        "  * ['경제', '구조가', '다룬다', '대한', '문서는', ... , '훈민정음', '훈민정음에', '훈민정음은']"
      ],
      "metadata": {
        "id": "XnvHxKRquxLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💡 인문학 연구자를 위한 핵심 포인트\n",
        "이러한 작동 방식을 이해하는 것은 매우 중요한다. 왜냐하면 이는 분석 결과에 직접적인 영향을 미치기 때문이다.\n",
        "\n",
        "* 문제점: '훈민정음', '훈민정음에', '훈민정음은'이 모두 다른 단어로 처리되면, '훈민정음'이라는 핵심 주제의 중요도가 여러 단어에 분산되어 정확한 분석이 어려울 수 있다.\n",
        "* 해결책: 더 정교한 분석을 위해서는 TfidfVectorizer의 기본 규칙 대신, **한국어 형태소 분석기(예: Mecab, Okt 등)**를 '단어 분해기(Tokenizer)'로 지정해주어야 한다. 형태소 분석기는 '훈민정음은'을 명사 '훈민정음'과 조사 '은'으로 정확하게 분리해주어, 우리가 원하는 분석을 가능하게 한다. (이는 다음 학습 단계에서 다룰 수 있는 심화 주제이다.)"
      ],
      "metadata": {
        "id": "pW-_fa1HwGaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF 결과의 인문학적 해석 및 활용\n",
        "\n",
        "1. '훈민정음' (TF-IDF: 문서1=0.567, 문서3=0.283)\n",
        "\n",
        "* 기계 해석: 문서1과 문서3은 '훈민정음'을 핵심 주제로 다루고 있다. 특히 문서1은 '훈민정음'을 더 집중적으로 언급하고 있다.\n",
        "\n",
        "* 인문학적 해석: TF-IDF는 '훈민정음'이라는 단어가 이 문서들의 **정체성(Identity)**을 규정하는 핵심 키워드임을 알려준다. 컴퓨터가 스스로 문서의 주제를 파악해낸 것이다.\n",
        "\n",
        " 연구 활용 방안:\n",
        "\n",
        " (문헌 검색) 만약 연구자의 연구 주제가 '훈민정음 창제 원리'라면, 방대한 사료 더미에서 '훈민정음'의 TF-IDF 값이 높은 문서들만 필터링하여 우선적으로 검토할 수 있다. 이는 수개월이 걸릴 수 있는 사료 검색 작업을 단 몇 분으로 단축시킨다.\n",
        "\n",
        " (내용 비교) 문서1과 문서3 모두 '훈민정음'을 다루지만, 중요도(점수)가 다른 점에 착안하여 \"왜 문서1이 더 높은 점수를 가질까?\"라는 새로운 연구 질문을 던질 수 있다. (예: 문서1은 창제 자체를, 문서3은 해례본의 관점을 다루기 때문은 아닐까?)\n",
        "\n",
        "2. '경제', '정책' (TF-IDF: 문서2=0.413)\n",
        "\n",
        "* 기계 해석: 문서2는 다른 문서들과는 완전히 다른 '경제'와 '정책'에 대해 이야기하고 있다. 이 단어들은 다른 문서에서는 전혀 찾아볼 수 없는, 문서2만의 고유한 키워드이다.\n",
        "\n",
        "* 인문학적 해석: TF-IDF는 여러 문서 간의 '다름'을 명확하게 드러낸다. '경제'라는 단어는 문서2를 다른 문서들과 구별 짓는 가장 강력한 지표가 된다.\n",
        "\n",
        " 연구 활용 방안:\n",
        "\n",
        " (문헌 자동 분류) 이 원리를 이용하면, 수만 건의 문서를 **주제별로 자동 분류(Clustering)**할 수 있다. 예를 들어, '경제', '세금', '농업' 등의 TF-IDF가 높은 문서들은 '경제사' 카테고리로, '외교', '국경', '사신' 등의 TF-IDF가 높은 문서들은 '대외관계사' 카테고리로 자동으로 묶을 수 있다.\n",
        "\n",
        "3. '문서이다' (TF-IDF: 0.283, 0.314, 0.283)\n",
        "\n",
        "* 기계 해석: '문서이다'라는 표현은 모든 문서에 골고루 등장하긴 하지만, 컴퓨터가 판단하기엔 내용적으로 별로 중요하지 않은 상투적인 표현 같다. 이 단어로는 각 문서의 고유한 특징을 알 수 없어 중요도를 낮게 매겼다.\n",
        "\n",
        "* 인문학적 해석: TF-IDF는 인간 연구자처럼 '맥락'을 이해하진 못하지만, 통계적으로 어떤 단어가 내용에 기여하지 않는 '기능어'나 '불용어(Stopword)'에 가까운지 놀랍도록 잘 판단한다.\n",
        "\n",
        " 연구 활용 방안:\n",
        "\n",
        " (노이즈 제거) 연구자는 TF-IDF 값이 전반적으로 낮은 단어들을 분석에서 제외함으로써, 분석의 핵심이 되는 중요한 단어들에만 집중할 수 있다. 이는 분석의 효율성과 정확도를 높여준다."
      ],
      "metadata": {
        "id": "4ZTfT5p1mSwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- [추가 코드] 각 문서의 핵심 키워드 추출하기 ---\n",
        "\n",
        "print(\"\\n▼ 각 문서별 TF-IDF 상위 키워드\")\n",
        "for i in range(len(documents)):\n",
        "    # i번째 문서의 벡터를 가져와서, TF-IDF 값이 높은 순으로 정렬\n",
        "    sorted_indices = tfidf_matrix[i].toarray().argsort()[0][::-1]\n",
        "\n",
        "    # 상위 5개 키워드만 추출\n",
        "    top_keywords = [(vocab[idx], tfidf_matrix[i, idx]) for idx in sorted_indices[:5]]\n",
        "\n",
        "    print(f\"[문서 {i+1}] 핵심 키워드:\")\n",
        "    for word, score in top_keywords:\n",
        "        print(f\"  - {word} (점수: {score:.2f})\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNf8DaVbwbag",
        "outputId": "a6e68657-7758-4ebd-9d1e-d639afd87c31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▼ 각 문서별 TF-IDF 상위 키워드\n",
            "[문서 1] 핵심 키워드:\n",
            "  - 훈민정음은 (점수: 0.40)\n",
            "  - 훈민정음에 (점수: 0.40)\n",
            "  - 대한 (점수: 0.40)\n",
            "  - 문자이다 (점수: 0.40)\n",
            "  - 위대한 (점수: 0.40)\n",
            "--------------------\n",
            "[문서 2] 핵심 키워드:\n",
            "  - 경제 (점수: 0.61)\n",
            "  - 조선 (점수: 0.31)\n",
            "  - 정책을 (점수: 0.31)\n",
            "  - 중요하다 (점수: 0.31)\n",
            "  - 다룬다 (점수: 0.31)\n",
            "--------------------\n",
            "[문서 3] 핵심 키워드:\n",
            "  - 훈민정음 (점수: 0.36)\n",
            "  - 창제 (점수: 0.36)\n",
            "  - 해례본은 (점수: 0.36)\n",
            "  - 원리와 (점수: 0.36)\n",
            "  - 중요한 (점수: 0.36)\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF 가중치 행렬(표) 정리 코드\n",
        "\n",
        "위의 행렬(표)를 각 문서의 주제가 명확하게 드러내는 코드를 추가하였다.\n",
        "\n",
        "* 문서 1은 '훈민정음' 자체에, 문서 2는 '경제 정책'에, 문서 3은 '훈민정음 해례본'에 대해 이야기하고 있음을 컴퓨터가 자동으로 요약해 준 것이다.\n",
        "\n",
        "* 이것이 바로 TF-IDF를 활용한 핵심 키워드 추출 기능이다."
      ],
      "metadata": {
        "id": "GJuaW5I1wkEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📜 실습: 반야부 계열 경전으로 배우는 TF-IDF 텍스트 분석\n",
        "\n",
        "대표적인 반야(般若) 사상 경전인 『금강경』, 『대반야바라밀다경』, **『반야심경』**의 한문 원문을 사용하여 TF-IDF 분석을 진행한다.\n",
        "\n",
        "### 🎯 실습 목표 및 의의\n",
        "세 경전은 모두 '반야(지혜)'와 '공(空)'이라는 핵심 사상을 공유한다. 하지만 그 형식과 강조점에는 미묘한 차이가 있다.\n",
        "\n",
        "* 금강경: 수보리와의 대화 형식, '상(相)'에 대한 집착을 깨는 데 초점.\n",
        "* 대반야경: 부처님의 설법에 모인 수많은 대중들을 상세히 묘사하는 서사적 특징.\n",
        "* 반야심경: 반야 사상의 정수를 극도로 압축한 철학적 요약.\n",
        "\n",
        "이번 실습의 목표는 **컴퓨터가 TF-IDF를 통해, 인간 연구자처럼 텍스트를 읽지 않고도 이 세 경전의 고유한 특징과 주제어를 자동으로 추출해낼 수 있는지 확인**한다."
      ],
      "metadata": {
        "id": "KSN-im5XyKCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ 1단계: 데이터 준비 및 코드 작성\n",
        "세 경전의 한문 원문 일부를 파이썬 리스트에 담아 준비한다.\n",
        "\n",
        "#### 📜 대상 텍스트 출전 정보\n",
        "1. 금강반야바라밀경 (金剛般若波羅蜜經)\n",
        "* 경전명: 금강반야바라밀경 (金剛般若波羅蜜經)\n",
        "* 고려대장경 번호: K-0013\n",
        "* 역자: 후진(後秦) 시대 구마라집(鳩摩羅什) 한역\n",
        "* 실습 예문 수록 부분: 경전의 시작부터 세 번째 품(分)까지의 내용.\n",
        "  * 제1 법회인유분(法會因由分)\n",
        "  *  제2 선현기청분(善現起請分)\n",
        "  * 제3 대승정종분(大乘正宗分)\n",
        "2. 대반야바라밀다경 (大般若波羅蜜多經)\n",
        "* 경전명: 대반야바라밀다경 (大般若波羅蜜多經)\n",
        "* 고려대장경 번호: K-0001\n",
        "* 역자: 당(唐)나라 시대 현장(玄奘) 한역\n",
        "* 실습 예문 수록 부분: 총 600권으로 이루어진 경전의 제1권(第一卷) 시작 부분.\n",
        "  * 초분(初分)의 제1 연기품(緣起品) 내용의 일부에 해당.\n",
        "3. 반야바라밀다심경 (般若波羅蜜多心經)\n",
        "* 경전명: 반야바라밀다심경 (般若波羅蜜多心經)\n",
        "* 고려대장경 번호: K-0020\n",
        "* 역자: 당(唐)나라 시대 현장(玄奘) 한역\n",
        "* 실습 예문 수록 부분: 한 권으로 이루어진 경전 전체에 해당.\n",
        "\n",
        "이 정보들은 동국대학교에서 운영하는 불교기록문화유산 아카이브(ABC)에서 수집한 내용이다."
      ],
      "metadata": {
        "id": "vxTRmFGGLVeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-1. 분석 대상 텍스트 준비\n",
        "\n",
        "documents = [\n",
        "    # 문서 1: 금강반야바라밀경 (Geumgang-gyeong)\n",
        "    \"如是我聞一時佛在舍衛國祇樹給孤獨園與大比丘衆千二百五十人俱爾時世尊食時著衣持鉢入舍衛大城乞食於其城中次第乞已還至本處飯食訖收衣鉢洗足已敷座而坐時長老須菩提在大衆中卽從座起偏袒右肩右膝著地合掌恭敬而白佛言希有世尊如來善護念諸菩薩善付囑諸菩薩世尊善男子善女人發阿耨多羅三藐三菩提心應云何住云何降伏其心佛言善哉善哉須菩提如汝所說如來善護念諸菩薩善付囑諸菩薩汝今諦聽當爲汝說善男子善女人發阿耨多羅三藐三菩提心應如是住如是降伏其心唯然世尊願樂欲聞佛告須菩菩薩摩訶薩應如是降伏其心所有一切衆生之類若卵生若胎生若濕生若化生若有色若無色若有想若無想若非有想非無想我皆令入無餘涅槃而滅度之如是滅度無量無數無邊衆生實無衆生得滅度者何以故須菩提若菩薩有我相人相衆生相壽者相卽非菩薩\",\n",
        "\n",
        "    # 문서 2: 대반야바라밀다경 (Dae-banya-baramilda-gyeong)\n",
        "    \"如是我聞一時薄伽梵住王舍城鷲峯山頂與大苾芻衆千二百五十人俱皆阿羅漢諸漏已盡無復煩惱得眞自在心善解脫慧善解脫如調慧馬亦如大龍已作所作已辦所辦棄諸重擔逮得己利盡諸有結正知解脫至心自在第一究竟除阿難陁獨居學地得預流果大迦葉波而爲上首復有五百苾芻尼衆皆阿羅漢大勝生主而爲上首復有無量鄔波索迦鄔波斯迦皆見聖諦復有無量無數菩薩摩訶薩衆一切皆得陁羅尼門三摩地門住空無相無分別願已得諸法平等性忍具足成就四無礙解凡所演說辯才無盡於五神通自在遊戲所證智斷永無退失言行威肅聞皆敬受勇猛精進離諸懈怠能捨親財不顧身命離矯離誑無染無求等爲有情而宣正法契深法忍窮最極趣得無所畏其心泰然超衆魔境出諸業障摧滅一切煩惱怨敵建正法幢伏諸邪論聲聞獨覺不能測量得心自在得法自在業惑見障皆已解脫擇法辯說無不善巧入深緣起生滅法門離見隨眠捨諸纏結智慧通達諸聖諦理曾無數劫發弘誓願容貌熙怡先言接引遠離嚬蹙辭韻淸和讚頌善巧辯才無滯處無邊衆威德肅然抑揚自在都無所畏多俱胝劫巧說無盡於諸法門勝解觀察如幻如陽焰如夢如水月如響如空花如像如光影如變化事如尋香城雖皆無實而現似有離下劣心說法無畏能隨證入無量法門善知有情心行所趣以微妙慧而度脫之於諸有情心無罣礙成就最上無生法忍善入諸法平等性智甚深法性能如實知隨其所應巧令悟入能善宣說緣起法門攝受無邊佛國大願於十方界無數諸佛等持正念常現在前諸佛出世皆能歷事亦能勸請轉正法輪不般涅槃度無量衆善能伏滅一切有情種種見纏諸煩惱焰湏臾遊戲百千等持引發無邊殊勝功德此諸菩薩具如是等妙功德海設經無量俱胝大劫歎不能盡\",\n",
        "\n",
        "    # 문서 3: 반야바라밀다심경 (Banya-simgyeong)\n",
        "    \"觀自在菩薩行深般若波羅蜜多時照見五薀皆空度一切苦厄舍利子色不異空空不異色色卽是空空卽是色受想行識亦復如是舍利子是諸法空相不生不滅不垢不淨不增不減是故空中無色無受想行識無眼耳鼻舌身意無色聲香味觸法無眼界乃至無意識界無無明亦無無明盡乃至無老死亦無老死盡無苦集滅道無智亦無得以無所得故菩提薩埵依般若波羅蜜多故心無罣礙無罣礙故無有恐怖遠離顚倒夢想究竟涅槃三世諸佛依般若波羅蜜多故得阿耨多羅三藐三菩提故知般若波羅蜜多是大神呪是大明呪是無上呪是無等等呪能除一切苦眞實不虛故說般若波羅蜜多呪卽說呪曰揭帝揭帝般羅揭帝般羅僧揭帝菩提僧莎訶\"\n",
        "]"
      ],
      "metadata": {
        "id": "3Nyc2aOmxGsS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L_4JtP3wNXn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ 2단계: TF-IDF 분석 코드 실행\n",
        "이제 TF-IDF 모델을 만들고, 각 경전의 핵심 키워드를 추출하는 전체 코드를 실행한다."
      ],
      "metadata": {
        "id": "yPuOR5pCLeGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-1. 라이브러리 불러오기\n",
        "import jieba\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# 2-2. 사용자 사전(User Dictionary)에 중요 단어 추가\n",
        "# 이 과정을 통해 '반야바라밀다' 같은 단어가 분해되지 않도록 한다.\n",
        "important_words = [\n",
        "    '金剛般若波羅蜜經', '大般若波羅蜜多經', '般若波羅蜜多心經', '般若波羅蜜多',\n",
        "    '須菩提', '世尊', '菩薩', '摩訶薩', '比丘', '阿耨多羅三藐三菩提',\n",
        "    '舍衛國', '祇樹給孤獨園', '我相', '人相', '衆生相', '壽者相',\n",
        "    '薄伽梵', '王舍城', '阿羅漢', '迦葉波', '苾篘', '無生法忍', '緣起',\n",
        "    '觀自在菩薩', '五蘊', '舍利子', '空', '涅槃', '揭帝揭帝'\n",
        "]\n",
        "for word in important_words:\n",
        "    jieba.add_word(word)\n",
        "\n",
        "# 2-3. 단어 분해기(Tokenizer) 정의\n",
        "def jieba_tokenizer(text):\n",
        "    return jieba.lcut(text)\n",
        "\n",
        "# 2-4. TF-IDF 벡터화 도구 생성 및 적용\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=jieba_tokenizer)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# 2-5. 각 문서별 상위 키워드 추출 및 출력\n",
        "vocab = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"\\n▼▽▼▽ 각 경전별 TF-IDF 상위 키워드 분석 결과 ▼▽▼▽\\n\")\n",
        "for i in range(len(documents)):\n",
        "    doc_name = [\"금강경\", \"대반야경\", \"반야심경\"][i]\n",
        "    sorted_indices = tfidf_matrix[i].toarray().argsort()[0][::-1]\n",
        "\n",
        "    # 상위 7개 키워드만 추출\n",
        "    top_keywords = [(vocab[idx], tfidf_matrix[i, idx]) for idx in sorted_indices[:7]]\n",
        "\n",
        "    print(f\"📖 [문서 {i+1}: {doc_name}]의 핵심 키워드:\")\n",
        "    for word, score in top_keywords:\n",
        "        print(f\"  - {word} (중요도 점수: {score:.3f})\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meZ33UkKLcvb",
        "outputId": "9d227c95-f7d9-4c63-b576-628ec466be00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▼▽▼▽ 각 경전별 TF-IDF 상위 키워드 분석 결과 ▼▽▼▽\n",
            "\n",
            "📖 [문서 1: 금강경]의 핵심 키워드:\n",
            "  - 若 (중요도 점수: 0.401)\n",
            "  - 菩薩 (중요도 점수: 0.305)\n",
            "  - 世尊 (중요도 점수: 0.229)\n",
            "  - 衆 (중요도 점수: 0.218)\n",
            "  - 善 (중요도 점수: 0.174)\n",
            "  - 降伏 (중요도 점수: 0.172)\n",
            "  - 須菩提 (중요도 점수: 0.172)\n",
            "----------------------------------------\n",
            "📖 [문서 2: 대반야경]의 핵심 키워드:\n",
            "  - 皆 (중요도 점수: 0.228)\n",
            "  - 得 (중요도 점수: 0.214)\n",
            "  - 在 (중요도 점수: 0.195)\n",
            "  - 衆 (중요도 점수: 0.195)\n",
            "  - 有情 (중요도 점수: 0.171)\n",
            "  - 無 (중요도 점수: 0.152)\n",
            "  - 有 (중요도 점수: 0.130)\n",
            "----------------------------------------\n",
            "📖 [문서 3: 반야심경]의 핵심 키워드:\n",
            "  - 是 (중요도 점수: 0.475)\n",
            "  - 呪 (중요도 점수: 0.356)\n",
            "  - 無 (중요도 점수: 0.315)\n",
            "  - 般若波羅蜜多 (중요도 점수: 0.297)\n",
            "  - 亦 (중요도 점수: 0.181)\n",
            "  - 想 (중요도 점수: 0.135)\n",
            "  - 卽 (중요도 점수: 0.135)\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###✨ 단계별 코드 설명\n",
        "\n",
        "🚀 데이터 준비 (1-1)\n",
        "\n",
        "한문 원문을 리스트에 각각의 문자열로 준비하면 다음과 같은 세 가지 결정적인 장점이 있다.\n",
        "* 1.리스트의 특징: 여러 개의 데이터(이 경우, 긴 문자열)를 하나의 변수(하나의 묶음) 안에 담을 수 있다.\n",
        "* 1-1. 분석에서의 장점: 금강경, 대반야경, 반야심경 원문을 각각 다른 변수에 흩어놓는 대신, documents라는 하나의 '책꽂이'에 모두 모아놓으니 데이터가 아주 깔끔해진다. 데이터를 관리하고 전달하기가 매우 편리해짐을 뜻한다.\n",
        "* 2.리스트의 특징: 리스트에 들어있는 데이터는 정해진 순서가 있고, 각 데이터는 0부터 시작하는 **고유 번호(인덱스, index)**를 자동으로 부여받는다.\n",
        "* 2-1. 분석에서의 장점: 이 '고유 번호' 덕분에 우리는 분석 결과를 원래의 텍스트와 헷갈리지 않고 정확하게 연결할 수 있다.\n",
        "* 2-2. 만약 순서나 번호가 없다면, 컴퓨터가 분석한 결과가 수많은 텍스트 중 과연 어떤 텍스트에 대한 것인지 알기 어렵다. 리스트의 '순서와 번호'는 분석 결과의 신뢰성을 보장하는 주소 역할이다.\n",
        "* 3.리스트의 특징: 파이썬에서 여러 개의 데이터를 다룰 때 가장 기본적이고 표준적인 방식이다.\n",
        "* 3-1. 분석에서의 장점: scikit-learn의 TfidfVectorizer와 같은 대부분의 텍스트 분석 도구들은 데이터를 입력받을 때, 바로 이 '리스트' 형태로 받도록 설계되었다. 마치 A4 용지를 복사기에 넣는 것처럼, 텍스트를 '리스트'라는 표준 규격에 맞춰 준비하면 어떤 분석 도구에든 쉽게 넣고 작동시킬 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "🚀 사용자 사전 정의 (2-2)\n",
        "\n",
        "분석 대상인 한문(漢文)과 동일한 형태로 단어를 추가하셨기 때문에, jieba가 '須菩提'나 '般若波羅蜜多' 같은 고유 명사와 핵심 불교 용어를 분해하지 않고 정확하게 하나의 단위로 인식할 수 있다. 이것이 분석의 질을 높이는 가장 중요한 단계이다.\n",
        "\n",
        "\n",
        "🚀 토크나이저 적용 (2-3, 2-4)\n",
        "\n",
        "jieba를 사용하는 jieba_tokenizer 함수를 올바르게 정의했고, 이 함수를 TfidfVectorizer(tokenizer=...)에 인자로 전달하여 기본 토크나이저를 성공적으로 대체함.\n",
        "\n",
        "\n",
        "🚀 결과 추출 및 출력 (2-5)\n",
        "\n",
        "단순히 복잡한 숫자 행렬만 출력하는 것이 아니라, 각 문서별로 TF-IDF 점수가 높은 상위 7개 키워드를 추출하여 그 점수와 함께 보기 쉽게 출력하도록 구현한다.\n"
      ],
      "metadata": {
        "id": "S7KKO06XNfdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. 결과 분석: 컴퓨터가 발견한 경전별 '문체적 특징'\n",
        "위의 TF-IDF 결과는 단순히 내용의 '주제'뿐만 아니라, 각 경전이 이야기를 풀어가는 고유한 '서술 방식'과 '문체(style)'를 컴퓨터가 통계적으로 포착했음을 보여주는 것이다.\n",
        "\n",
        "### 📖 [문서 1: 금강경]의 핵심 키워드: 若, 菩薩, 世尊, 須菩提 등\n",
        "\n",
        "**결과 해석**:\n",
        "* 가장 높은 점수를 받은 단어는 若(만약 약)이다. 금강경의 내용을 살펴보면, 부처님은 수보리의 질문에 답하며 \"만약 어떤 보살이 ~한다면(若菩薩...)\", \"만약 ~라는 생각이 있다면(若有...相)\" 과 같이 가정과 질문을 반복하는 구조로 설법을 펼친다.\n",
        "* TF-IDF는 바로 이 금강경 특유의 변증법적(dialectic)이고 가정법적인 서술 구조를 若라는 단어를 통해 정확하게 포착한 것이다. 菩薩, 世尊, 須菩提 등은 이 문답의 핵심 인물들로서, 내용과 구조를 모두 잘 보여주는 결과이다.\n",
        "\n",
        "### 📖 [문서 2: 대반야경]의 핵심 키워드: 皆, 得, 在, 有情 등\n",
        "**결과 해석**:\n",
        "* 가장 눈에 띄는 키워드는 皆(다 개)이다. 대반야경 도입부는 설법에 모인 수많은 대중을 소개하며 \"모두 아라한이었고(皆阿羅漢)\", \"모두 성인의 진리를 보았고(皆見聖諦)\" 와 같이, 특정 경지에 오른 존재들을 **'열거하고 묘사'**하는 특징을 가진다.\n",
        "* TF-IDF는 皆라는 키워드를 통해, 이 텍스트가 다수의 대상을 하나로 묶어 그 공통된 상태와 공덕을 나열하는 문체적 특징을 가졌음을 간파한 것이다.\n",
        "\n",
        "### 📖 [문서 3: 반야심경]의 핵심 키워드: 是, 呪, 無, 般若波羅蜜多 등\n",
        "**결과 해석**:\n",
        "* 가장 높은 점수의 단어는 是(이 시)와 呪(주문 주)이다. 반야심경의 결론부는 \"...가장 신비한 주문이며(是大神呪), 가장 밝은 주문이며(是大明呪)...\" 와 같이 '이것은 ~이다(是...)' 라는 선언적 어조로 그 위대함을 강조한다.\n",
        "* TF-IDF는 반야심경의 핵심 철학인 無(없을 무)와 함께, 결론부의 선언적(declarative)이고 주문(mantra)을 강조하는 구조적 특징을 是와 呪를 통해 정확하게 추출한 것이다."
      ],
      "metadata": {
        "id": "DASGnsMMPBy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💡 2. 디지털 인문학적 활용 방안\n",
        "\n",
        "이러한 결과는 단순한 키워드 목록을 넘어, 다음과 같은 깊이 있는 인문학 연구로 이어질 수 있다.\n",
        "\n",
        "1. 문체 분석 (Stylometry): 작가와 시대의 '문체 지문' 찾기\n",
        "활용 방안: 이번 결과는 TF-IDF가 내용뿐 아니라 문체(style)를 정량화할 수 있음을 보여준다. 若을 즐겨 쓰는 텍스트, 皆를 즐겨 쓰는 텍스트로 특징이 나뉜다. 이 원리를 확장하여 특정 저자나 시대의 문헌들을 분석, 그들의 **'문체 지문(stylistic fingerprint)'**을 찾아낼 수 있다. 이는 저자 판별 연구나 시대별 문체 변천사 연구의 강력한 근거가 된다.\n",
        "\n",
        "2. 텍스트 장르 및 구조 분석 (Genre and Structural Analysis)\n",
        "활용 방안: 키워드의 종류는 텍스트의 장르를 암시한다. 若은 '논증/문답형', 皆는 '서사/묘사형', 呪는 '의례/주문형' 텍스트로 잠정 분류가 가능하다. 긴 경전 전체를 분석하여 어떤 부분(章)이 서론이고, 핵심 교리이며, 결론의 다라니인지 자동으로 구조를 파악하는 연구도 가능하다.\n",
        "\n",
        "3. 불용어(Stopword) 처리의 중요성 인식 및 반복 연구\n",
        "활용 방안: 이번 분석은 중요한 방법론적 시사점을 준다. 若, 皆, 是 등은 문체를 보여주지만, 때로는 내용 이해에 '노이즈(noise)'가 될 수 있다. 연구자는 1차 분석 결과를 보고, 이 단어들을 **'불용어(분석에서 제외할 단어)'**로 지정 후 재분석하여, 그 다음으로 중요한 내용어들을 심층적으로 탐색하는 등 분석을 단계적으로 심화시킬 수 있다."
      ],
      "metadata": {
        "id": "pGpTqedMQKrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [실습] 해보자!"
      ],
      "metadata": {
        "id": "XfgjAHebQeo0"
      }
    }
  ]
}
