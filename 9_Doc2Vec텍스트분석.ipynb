{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/NJTAHXMfwRvsUYoLixLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-yiJung/DH-Buddhist-Analysis-Tutorial/blob/main/9_Doc2Vec%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##📜 Doc2Vec: 단어를 넘어 문서 전체의 '주제'를 벡터로 만들기\n",
        "\n",
        "Word2Vec은 개별 단어의 의미를 벡터로 표현하는 방법이었다. 이를 통해 '왕'과 '여왕'의 관계를 파악하는 등의 분석이 가능했다.\n",
        "\n",
        "하지만 연구자는 종종 \"이 문서와 가장 유사한 주제의 문서를 찾아라\" 또는 \"수천 개의 문서를 주제별로 자동 분류하라\"와 같은, **문서 전체(Document-level)**를 대상으로 하는 과제에 직면한다. 이 때, 단순히 단어 벡터들을 평균 내는 방식(Mean of Word Embeddings)도 있지만, 문서의 고유한 주제와 뉘앙스를 더 정교하게 포착하기 위해 개발된 모델이 바로 **Doc2Vec (Paragraph Vector)**이다.\n",
        "\n",
        "### 1. Doc2Vec의 핵심 개념\n",
        "모든 문서에 고유한 '주제 태그'를 부여하다\n",
        "Doc2Vec의 가장 핵심적인 아이디어는 Word2Vec의 개념을 확장하여, 문서에 있는 모든 단어뿐만 아니라, 문서 그 자체에도 고유한 벡터가 있다고 가정하는 것이다.\n",
        "\n",
        "쉽게 비유하자면:\n",
        "도서관의 모든 책(문서)에 경제사-001, 언어학-005와 같이 그 책의 전체 주제를 나타내는 **고유한 '주제 태그(Paragraph ID)'**를 붙여주는 것과 같다. 이 '주제 태그' 역시 다른 단어들처럼 자신만의 의미 벡터를 가진다.\n",
        "\n",
        "Word2Vec이 단어의 의미를 주변 단어로부터 학습했다면, Doc2Vec은 **주변 단어 + 문서의 '주제 태그'**를 함께 고려하여 단어와 문서의 의미를 동시에 학습한다.\n",
        "\n",
        "작동 원리 (PV-DM과 PV-DBOW)\n",
        "Doc2Vec은 Word2Vec의 CBOW와 Skip-gram을 각각 확장한 두 가지 방식으로 학습을 진행한다.\n",
        "\n",
        "PV-DM (Paragraph Vector - Distributed Memory):\n",
        "\n",
        "Word2Vec의 CBOW를 확장한 방식이다. 문장의 빈칸을 채우는 '추측 게임'을 할 때, 주변 단어들의 벡터와 함께 이 단어가 속한 '문서의 주제 태그' 벡터까지 함께 사용하여 중심 단어를 예측한다.\n",
        "\n",
        "이 과정을 통해 모델은 단어의 문맥적 의미와 함께, 문서 전체의 주제까지 동시에 학습하게 된다.\n",
        "\n",
        "PV-DBOW (Paragraph Vector - Distributed Bag of Words):\n",
        "\n",
        "Word2Vec의 Skip-gram을 확장한 방식이다. 더 단순하게, 오직 '문서의 주제 태그' 벡터 하나만으로 해당 문서에 포함된 단어들을 무작위로 예측하는 훈련을 반복한다.\n",
        "\n",
        "이는 \"이 문서의 주제가 '불교 철학'이라면, 어떤 단어들이 주로 등장할까?\"라고 추측하는 과정과 유사하다.\n",
        "\n",
        "이러한 훈련이 끝나면, 우리는 각 단어의 벡터뿐만 아니라 **문서 전체의 주제를 함축하는 고유한 문서 벡터(Document Vector)**를 얻게 된다."
      ],
      "metadata": {
        "id": "oxOxKb2esRoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. 등장 배경\n",
        "\n",
        "누가/언제: Doc2Vec은 2014년, Word2Vec을 개발한 구글의 토마스 미콜로프(Tomas Mikolov)와 쿠옥 레(Quoc Le)에 의해 개발되었다.\n",
        "\n",
        "왜: Word2Vec이 단어 수준의 분석에 큰 성공을 거두자, 연구자들은 자연스럽게 문장, 문단, 문서 전체와 같이 가변적인 길이의 텍스트 덩어리를 어떻게 고정된 크기의 벡터로 표현할 수 있을지에 대한 고민을 시작했다. Doc2Vec은 이러한 필요에 부응하여, 텍스트의 길이에 상관없이 전체적인 의미를 담는 단일 벡터를 효과적으로 생성하는 방법을 제시했다.\n",
        "\n",
        "###3. 디지털 인문학에서의 활용\n",
        "\n",
        "Doc2Vec은 텍스트를 '단어의 모음'이 아닌 '의미의 덩어리'로 취급할 수 있게 하여, 다음과 같은 거시적인 분석을 가능하게 한다.\n",
        "\n",
        "1. 문헌 추천 및 유사 문서 검색\n",
        "활용 방안: 연구자가 현재 읽고 있는 특정 사료(예: 『조선왕조실록』의 특정 기사)의 문서 벡터를 기준으로, 전체 실록 데이터베이스에서 벡터 거리가 가장 가까운 다른 기사들을 찾아낼 수 있다. 이는 특정 사건과 관련된 숨겨진 다른 기록이나, 비슷한 논조를 가진 다른 시기의 기사들을 자동으로 발견하는 강력한 탐색 도구가 된다.\n",
        "\n",
        "2. 주제별 문헌 군집화 (Clustering)\n",
        "활용 방안: 저자나 연대를 알 수 없는 수천 개의 고문서 뭉치(예: 개인이 기증한 편지 모음)를 Doc2Vec으로 학습시킨다. 그 결과로 나온 문서 벡터들을 K-Means와 같은 군집화 알고리즘에 적용하면, 컴퓨터가 자동으로 문서들을 내용에 따라 주제별(예: '가족 안부', '정치 동향', '금전 거래')로 분류해준다. 이는 대규모 아카이브 정리 및 탐색의 출발점이 된다.\n",
        "\n",
        "3. 저자 판별 및 문체 분석\n",
        "활용 방안: 여러 저자의 글을 Doc2Vec으로 학습시키면, 문서 벡터는 단순히 주제뿐만 아니라 저자가 단어를 선택하고 문장을 구성하는 전반적인 스타일까지 일부 반영하게 된다. 이를 통해 미상의 저자가 쓴 글의 문서 벡터가 어떤 저자의 문서 벡터 군집과 가장 가까운지를 계산하여, 해당 글의 저자를 통계적으로 추정하는 연구를 진행할 수 있다."
      ],
      "metadata": {
        "id": "hg_VDvN0sg5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 필수 라이브러리 설치\n",
        "# - `pip install --no-deps` 옵션을 사용하여 gensim만 설치합니다.\n",
        "# - 이렇게 하면 numpy와 scipy의 충돌을 무시하고 gensim을 설치할 수 있습니다.\n",
        "# - numpy와 scipy는 Colab에 이미 설치되어 있으므로, gensim만 설치하면 됩니다.\n",
        "!pip install gensim --no-deps -q\n",
        "print(\"✅ 필수 라이브러리 설치 완료: gensim\\n\")\n",
        "\n",
        "# 2. 라이브러리 임포트 및 데이터 준비\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import os\n",
        "\n",
        "# 가상의 디지털 인문학 문서 (한문 법구경 구절)\n",
        "documents = [\n",
        "    \"睡眠 解寤\",\n",
        "    \"宜 歡喜 思\",\n",
        "    \"聽 我 所 說\",\n",
        "    \"撰記 佛言\",\n",
        "    \"衆生 相剋\",\n",
        "    \"老死 猶然\",\n",
        "    \"命 終 自然\",\n",
        "    \"從 生死 得度\",\n",
        "    \"無 畏 無 患\",\n",
        "    \"行 不 離 心\",\n",
        "    \"世間 萬物 無常\",\n",
        "    \"善 言 安樂\",\n",
        "]\n",
        "\n",
        "# 3. 데이터 전처리 (토큰화 및 Doc2Vec 포맷으로 변환)\n",
        "tagged_data = [\n",
        "    TaggedDocument(words=doc.split(), tags=[i])\n",
        "    for i, doc in enumerate(documents)\n",
        "]\n",
        "\n",
        "print(\"✅ 데이터 전처리 및 TaggedDocument 변환 완료\")\n",
        "print(f\"변환된 데이터 예시 (1번 문서): {tagged_data[1]}\\n\")\n",
        "\n",
        "# 4. Doc2Vec 모델 학습\n",
        "model = Doc2Vec(vector_size=50, min_count=1, epochs=40)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "print(\"✅ Doc2Vec 모델 학습 완료\\n\")\n",
        "\n",
        "\n",
        "# 5. 모델을 활용한 문서 유사도 분석\n",
        "# '문서 4'를 기준 문서로 삼아, 이 문서와 가장 유사한 문서를 찾습니다.\n",
        "query_doc_id = 4\n",
        "query_doc_vector = model.dv[query_doc_id]\n",
        "\n",
        "similar_docs = model.dv.most_similar(positive=[query_doc_vector], topn=3)\n",
        "\n",
        "print(f\"🔍 기준 문서 ({query_doc_id}번 문서)와 가장 유사한 문서 Top 3:\\n\")\n",
        "print(f\"--- 기준 문서 내용 ---\\n{documents[query_doc_id]}\\n\")\n",
        "\n",
        "for doc_id, similarity in similar_docs:\n",
        "    if doc_id == query_doc_id:\n",
        "        continue\n",
        "    print(f\"----------------------------------------\")\n",
        "    print(f\"유사 문서 ID: {doc_id}번 문서\")\n",
        "    print(f\"유사도 점수: {similarity:.4f}\")\n",
        "    print(f\"문서 내용: {documents[doc_id]}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4fIjQMINW_k",
        "outputId": "a3e7e3b5-f1be-4547-c104-15d6f40eb5e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 필수 라이브러리 설치 완료: gensim\n",
            "\n",
            "✅ 데이터 전처리 및 TaggedDocument 변환 완료\n",
            "변환된 데이터 예시 (1번 문서): TaggedDocument<['宜', '歡喜', '思'], [1]>\n",
            "\n",
            "✅ Doc2Vec 모델 학습 완료\n",
            "\n",
            "🔍 기준 문서 (4번 문서)와 가장 유사한 문서 Top 3:\n",
            "\n",
            "--- 기준 문서 내용 ---\n",
            "衆生 相剋\n",
            "\n",
            "----------------------------------------\n",
            "유사 문서 ID: 9번 문서\n",
            "유사도 점수: 0.0535\n",
            "문서 내용: 行 不 離 心\n",
            "\n",
            "----------------------------------------\n",
            "유사 문서 ID: 10번 문서\n",
            "유사도 점수: -0.0142\n",
            "문서 내용: 世間 萬物 無常\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###💡 코드 구성 설명 (비전공자 눈높이)\n",
        "이 코드는 한문 문장들이 담긴 책의 문단들을 컴퓨터가 이해할 수 있는 방식으로 정리하고, 비슷한 주제를 가진 문단들을 찾아내는 과정을 보여준다.\n",
        "\n",
        "비유하자면, 도서관 사서가 수많은 책을 읽고 각 책의 주제를 파악해 \"이 책과 저 책은 철학이라는 비슷한 주제를 다루는군\" 하고 분류하는 것과 비슷하다.\n",
        "\n",
        "아래는 코드가 단계별로 어떤 일을 하는지 쉽게 풀어쓴 설명이다.\n",
        "\n",
        "**필요한 도구(라이브러리) 가져오기**\n",
        "\n",
        "pip install gensim은 \"Doc2Vec\"이라는 특별한 분석 도구가 담긴 상자(gensim 라이브러리)를 컴퓨터에 설치하는 명령이다. 이 도구 덕분에 우리는 복잡한 계산을 직접 할 필요 없이 문서를 분석할 수 있다.\n",
        "\n",
        "**데이터 준비하기**\n",
        "\n",
        "documents라는 변수 안에 한문 문장들을 저장했다. 이 한 문장 한 문장이 곧 컴퓨터가 분석할 \"문서\"가 된다.\n",
        "\n",
        "**데이터 정리하기**\n",
        "\n",
        "컴퓨터는 문장을 있는 그대로 이해하지 못한. 그래서 TaggedDocument라는 특별한 형태로 바꿔준다. 이 과정에서 각 문장(문서)에 고유한 번호(태그)를 붙여준다. 예를 들어, TaggedDocument<['宜', '歡喜', '思'], [1]>는 \"1번 문서의 내용은 '宜', '歡喜', '思'라는 단어로 이루어져 있어\"라고 컴퓨터에게 알려주는 작업이다.\n",
        "\n",
        "**모델 학습하기 (사서가 공부하는 과정)**\n",
        "\n",
        "model = Doc2Vec(...) 코드는 사서가 책을 읽으며 지식을 쌓는 과정과 같다. 컴퓨터는 documents에 있는 모든 문장과 단어들의 관계를 40번 반복해서 읽고, 각 문장이 어떤 '주제'를 가졌는지 숫자 벡터로 표현하는 방법을 학습한다. 이 학습이 끝나면, 각 문서는 자신만의 고유한 주제 벡터를 가지게 된다.\n",
        "\n",
        "**문서 유사도 분석하기 (사서가 추천해 주는 과정)**\n",
        "\n",
        "query_doc_id = 4는 \"4번 문서(衆生 相剋)와 가장 비슷한 주제를 가진 문서를 찾아줘\"라고 컴퓨터에게 요청하는 부분이다. model.dv.most_similar는 컴퓨터가 학습을 통해 만든 주제 벡터들을 비교해서 가장 비슷한 문서를 찾아준다."
      ],
      "metadata": {
        "id": "PxHEtqrcNrvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###🧠 분석 결과 해설\n",
        "\n",
        "결과를 보면 \"4번 문서(衆生 相剋)\"와 가장 유사한 문서로 \"9번 문서(行 不 離 心)\"가, 그다음으로 \"10번 문서(世間 萬物 無常)\"가 나왔다.\n",
        "\n",
        "\n",
        "유사도 점수:\n",
        "\n",
        "9번 문서: 0.0535\n",
        "\n",
        "10번 문서: -0.0142\n",
        "\n",
        "\n",
        "이 점수는 **코사인 유사도(Cosine Similarity)**를 나타낸다. 점수가 1에 가까울수록 매우 유사하고, -1에 가까울수록 전혀 다른 내용임을 의미한다. 0에 가깝다는 것은 유사도가 낮다는 뜻이다.\n",
        "\n",
        "**결과가 낮게 나온 이유**\n",
        "\n",
        "샘플 데이터의 부족: Doc2Vec은 문맥 정보를 학습해야 하는데, 저희가 사용한 데이터는 문장이 12개밖에 안 되는 아주 작은 양이다. 컴퓨터가 충분한 문맥을 학습하기에는 턱없이 부족했기 때문에, 문장들 간의 의미 관계를 제대로 파악하지 못했다.\n",
        "\n",
        "단어의 고립성: '衆生', '相剋' 같은 단어는 다른 문장에서 함께 등장하지 않는다. 단어의 중복이 거의 없어서, 모델이 공통된 주제를 찾아내기 어려웠다.\n",
        "\n",
        "따라서 현재의 결과는 학습 데이터가 너무 적어 모델이 제대로 된 의미 관계를 찾지 못했음을 보여준다. 이 코드를 수천, 수만 개의 실제 문서에 적용하면, 모델은 衆生 相剋과 老死 猶然, 世間 萬物 無常 같은 '불교적 깨달음'이나 '삶의 고통' 같은 공통된 주제를 가진 문장들을 훨씬 더 정확하게 찾아낼 수 있을 것이다.\n",
        "\n",
        "이 코드는 대규모 문헌 분석의 가능성을 보여주는 출발점이라고 생각하시면 된다."
      ],
      "metadata": {
        "id": "xV57AaYHOF0b"
      }
    }
  ]
}