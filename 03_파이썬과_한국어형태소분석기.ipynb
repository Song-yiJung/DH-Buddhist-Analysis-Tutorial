{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6/88okVBHfkZL7hC9TNiF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-yiJung/DH-Buddhist-Analysis-Tutorial/blob/main/3_%ED%8C%8C%EC%9D%B4%EC%8D%AC%EA%B3%BC_%ED%95%9C%EA%B5%AD%EC%96%B4%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한국어 형태소 분석기 둘러보기: KoNLPy, Mecab, OKT, Kiwi 실습\n",
        "\n",
        "* 한국어 텍스트를 분석할 때 가장 먼저 만나게 되는 건 **형태소 분석기**이다. 이 도구들은 한국어 문장을 의미 있는 작은 단위(형태소)로 쪼개고, 품사 이름표를 붙여주는 중요한 역할을 한다.\n",
        "\n",
        "* 파이썬에서는 KoNLPy라는 통합 라이브러리를 통해 여러 형태소 분석기를 쉽게 사용할 수 있다.\n",
        "\n",
        "💡 형태소 분석기가 왜 이렇게 많을까?\n",
        "한국어는 복잡해서, 어떤 단어를 어떻게 쪼갤지, 어떤 품사로 볼지에 대한 '정답'이 하나가 아니다.\n",
        "\n",
        "* 정통적인 문법 규칙에 충실한 분석기가 있는가 하면,\n",
        "* 비정형적인 인터넷 글에 더 잘 맞는 분석기도 있고,\n",
        "* 머신러닝을 활용해 자동으로 패턴을 학습하는 분석기도 있다.\n",
        "\n",
        "이처럼 분석하려는 **텍스트의 종류(정돈된 소설 vs. 줄임말 많은 SNS)**와 연구 목적에 따라 더 잘 맞는 분석기가 다르다. 그래서 여러 분석기를 비교해보고 나에게 맞는 것을 선택하는 것이 중요하다!"
      ],
      "metadata": {
        "id": "i8PlhS3AqNJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. KoNLPy (코엔엘파이): 한국어 형태소 분석기의 통합 창구\n",
        "\n",
        "* KoNLPy 'Korean Natural Language Processing in Python'의 약자\n",
        "\n",
        "* 여러 한국어 형태소 분석기들을 파이썬에서 쉽고 통일된 방식으로 사용할 수 있도록 도와주는 통합 라이브러리.\n",
        "\n",
        "* KoNLPy 덕분에 우리는 각 분석기마다 다른 설치나 사용법을 일일이 익힐 필요 없이, KoNLPy를 통해 편리하게 접근할 수 있다."
      ],
      "metadata": {
        "id": "Tv27Uc_wq3ZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se3yyaHuqD-a",
        "outputId": "0dacc1c0-4aa9-4a91-ac1b-1b6b01c6c2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.2 konlpy-0.6.0\n",
            "✅ KoNLPy 라이브러리 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "# KoNLPy 라이브러리 설치 (코랩에 설치되어 있다면 'Requirement already satisfied' 메시지가 나옵니다.)\n",
        "!pip install konlpy #설명 함수 설명\n",
        "\n",
        "print(\"✅ KoNLPy 라이브러리 준비 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KoNLPy 라이브러리에서 Okt(Open Korean Text) 형태소 분석기 불러오기\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# Okt 객체 생성\n",
        "okt = Okt()\n",
        "\n",
        "# 분석할 샘플 한국어 문장\n",
        "sample_korean_sentence = \"아버지가 방에 들어가신다. 나는 학교에 간다. 정말 좋은 날씨!\"\n",
        "\n",
        "print(\"--- KoNLPy (Okt) 기본 분석 시작 ---\\n\")\n",
        "\n",
        "# 1. 문장을 형태소로 나누기 (어절 단위)\n",
        "# nouns(): 명사만 추출\n",
        "print(f\"** 명사 추출: {okt.nouns(sample_korean_sentence)}\")\n",
        "\n",
        "# 2. 문장을 형태소로 나누고 품사(Part-of-Speech) 태그 붙이기\n",
        "# pos(): 형태소와 품사 태그 쌍으로 추출\n",
        "print(f\"** 형태소 및 품사 태그: {okt.pos(sample_korean_sentence)}\")\n",
        "\n",
        "# 3. 문장을 어절 단위로 나누기 (띄어쓰기 기준)\n",
        "# morphs(): 형태소만 추출 (품사 태그 없음)\n",
        "print(f\"** 형태소만 추출: {okt.morphs(sample_korean_sentence)}\")\n",
        "\n",
        "# 4. 명사를 추출하고, 그 단어의 어미를 제외한 부분을 추출 (간단한 어간 추출과 유사)\n",
        "# phrases(): 구(phrase) 단위 추출 (주로 명사구)\n",
        "print(f\"** 구(phrase) 추출: {okt.phrases(sample_korean_sentence)}\")\n",
        "\n",
        "print(\"\\n-------------------------------------\")\n",
        "print(\"✅ KoNLPy (Okt) 기본 분석 실습 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM7pzLtEzVnl",
        "outputId": "02b53f76-6058-487f-c97b-26c4b27e6805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- KoNLPy (Okt) 기본 분석 시작 ---\n",
            "\n",
            "** 명사 추출: ['아버지', '방', '나', '학교', '간다', '정말', '날씨']\n",
            "** 형태소 및 품사 태그: [('아버지', 'Noun'), ('가', 'Josa'), ('방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb'), ('.', 'Punctuation'), ('나', 'Noun'), ('는', 'Josa'), ('학교', 'Noun'), ('에', 'Josa'), ('간다', 'Noun'), ('.', 'Punctuation'), ('정말', 'Noun'), ('좋은', 'Adjective'), ('날씨', 'Noun'), ('!', 'Punctuation')]\n",
            "** 형태소만 추출: ['아버지', '가', '방', '에', '들어가신다', '.', '나', '는', '학교', '에', '간다', '.', '정말', '좋은', '날씨', '!']\n",
            "** 구(phrase) 추출: ['아버지', '학교', '간다', '정말', '정말 좋은 날씨', '날씨']\n",
            "\n",
            "-------------------------------------\n",
            "✅ KoNLPy (Okt) 기본 분석 실습 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실습 결과 해석**\n",
        "\n",
        "위 코드를 실행하면 okt.nouns(), okt.pos(), okt.morphs(), okt.phrases() 각각의 결과가 출력된다.\n",
        "\n",
        "* okt.nouns(): 문장에서 명사만 깔끔하게 뽑아낸 목록을 보여준다. 텍스트의 핵심 주제를 파악할 때 유용하다.\n",
        "* okt.pos(): 각 형태소에 Noun (명사), Verb (동사), Adjective (형용사) 같은 품사 태그가 붙어있는 것을 확인할 수 있다. 이 정보는 단어의 문법적 역할을 이해하는 데 중요하다.\n",
        "* okt.morphs(): 품사 정보 없이 형태소 단위로만 쪼개진 목록을 보여준다.\n",
        "* okt.phrases(): 문장에서 의미 있는 **구(phrase)**를 추출한 목록을 보여준다. 주로 명사구를 추출해서 핵심 키워드나 개념을 파악하는 데 도움이 될 수 있다.\n",
        "\n",
        "이처럼 KoNLPy를 사용하면 단 몇 줄의 코드로 한국어 텍스트를 다양한 방식으로 쪼개고 분석할 수 있다."
      ],
      "metadata": {
        "id": "A0ckBJKhzd0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OKT (Open Korean Text): 비정형 텍스트에 강한 '트위터 출신'\n",
        "\n",
        "OKT는 한국어 형태소 분석기 중에서 특히 비정형적이고 구어체적인 텍스트를 분석하는 데 강점을 보이는 분석기이다.\n",
        "\n",
        "### 1. OKT는 누가, 왜 만들었을까? (개발 주체 및 배경)\n",
        "\n",
        "OKT의 원래 이름은 'Twitter' 형태소 분석기였다. 이름에서 알 수 있듯이, 2011년 **트위터(Twitter, 현재 X)**에서 개발한 한국어 형태소 분석기였다.\n",
        "\n",
        "* 개발 주체: 초기 개발은 트위터의 한국어 NLP(자연어 처리) 팀에서 진행되었다.\n",
        "\n",
        "* 개발 배경 및 목적: 당시 한국어 분석기들은 주로 신문 기사나 소설처럼 정돈된 텍스트에 최적화되었다. 하지만 트위터 같은 SNS에는 짧고, 구어체적이며, 신조어, 줄임말, 이모티콘, 띄어쓰기 오류 등이 빈번하게 사용되었다. 기존 분석기로는 이런 텍스트를 정확하게 처리하기 어려웠다. 따라서 트위터는 자신들의 플랫폼에 최적화된, 비정형적인 한국어 텍스트를 효율적으로 분석할 수 있는 형태소 분석기를 직접 개발하게 되었다.\n",
        "\n",
        "* 오픈 소스 전환: 트위터는 이 분석기를 오픈 소스로 공개하여, 다른 개발자와 연구자들도 자유롭게 사용하고 개선할 수 있도록 했다. 이후 'Open Korean Text'로 이름을 바꾸면서 더욱 범용적인 사용을 지향하게 되었다.\n",
        "\n",
        "### 2. OKT의 주요 특징 (무엇이 다를까?)\n",
        "\n",
        "OKT는 다음과 같은 독특한 특징들을 가지고 있다.\n",
        "\n",
        "* 비정형 텍스트 처리 강점:\n",
        "\n",
        "SNS 게시물, 인터넷 댓글, 채팅 기록, 웹툰 대사 등 띄어쓰기 오류가 많거나, 줄임말, 신조어가 빈번한 텍스트에 대해 비교적 뛰어난 분석 성능을 보여준다.\n",
        "\n",
        "ㅋㅋㅋ, ㅇㅈ, 핵꿀잼과 같은 비표준적인 표현도 어느 정도 인식하고 처리하려는 시도를 한다.\n",
        "\n",
        "* 간결한 구현: Mecab과 같은 C++ 기반의 복잡한 구현보다는 JVM(Java Virtual Machine) 환경에서 동작하며, 비교적 간결한 규칙 기반으로 구현되어 있다. 이는 파이썬 환경에서 설치 및 사용이 상대적으로 쉽다는 장점으로 이어진다.\n",
        "\n",
        "* 품사 태그셋: Mecab과는 다른 고유의 품사 태그셋을 사용한다. 예를 들어, 명사는 Noun, 동사는 Verb 등으로 표현되어 Mecab의 NNG, VV 등과 차이가 있다.\n",
        "\n",
        "* 빠른 속도 (상대적): Mecab만큼은 아니지만, 다른 일부 분석기들보다는 처리 속도가 빠르고 범용적으로 사용하기에 적합하다.\n",
        "\n",
        "### 3. 왜 KoNLPy에서 OKT를 불러와 사용할 수 있을까?\n",
        "\n",
        "OKT는 KoNLPy를 설치하면 별도의 추가 설치 없이 바로 사용할 수 있다. 이는 KoNLPy의 통합 모듈(Unified Module) 역할 덕분이다.\n",
        "\n",
        "KoNLPy의 역할: KoNLPy는 다양한 형태소 분석기들을 하나의 파이썬 인터페이스(Interface) 아래 통합한다. 즉, 각 분석기(Mecab, OKT, Kiwi 등)가 내부적으로 어떤 방식으로 작동하든 상관없이, 사용자는 konlpy.tag 모듈을 통해 일관된 방식으로 분석기를 불러와 사용할 수 있게 해준다.\n",
        "OKT와 KoNLPy의 연동: OKT는 KoNLPy에 포함된 형태로 제공되므로, pip install konlpy 명령어를 통해 KoNLPy를 설치하면 OKT도 함께 설치되어 바로 from konlpy.tag import Okt와 같이 불러와서 사용할 수 있게 된다. Mecab처럼 별도의 외부 시스템 설치 과정이 필요하지 않다."
      ],
      "metadata": {
        "id": "PzRae_AH0AtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mecab (메캅): 빠르고 정확한 '정통파' 분석기\n",
        "\n",
        "Mecab은 원래 일본에서 개발되었지만, 한국어 분석에도 뛰어나 많은 연구자와 개발자가 사용한다. 특히, 속도가 매우 빠르고 정통적인 문법 규칙에 기반한 분석이 정확하다는 장점이 있다. 대용량 텍스트나 비교적 정돈된 텍스트(예: 소설, 뉴스 기사) 분석에 강점을 보인다."
      ],
      "metadata": {
        "id": "y2tQloEtrHZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Kiwi (키위): 머신러닝 기반의 '현대 한국어' 전문가\n",
        "Kiwi는 한국어 형태소 분석기 중 비교적 최근에 개발된 도구로, 머신러닝(Machine Learning) 기술을 기반으로 현대 한국어의 복잡성과 변화하는 언어 현상을 유연하게 처리하는 데 강점을 가지고 있다.\n",
        "\n",
        "### 1. Kiwi는 누가, 왜 만들었을까? (개발 주체 및 배경)\n",
        "* 개발 주체: Kiwi는 2017년부터 개발되어 오픈 소스로 공개되었다.\n",
        "\n",
        "* 개발 배경 및 목적:\n",
        "기존 형태소 분석기들(예: Mecab)은 주로 수작업으로 구축된 방대한 사전과 규칙에 의존하는 방식이 많았다. 이 방식은 정확하지만, 신조어나 띄어쓰기 오류, 빠르게 변화하는 현대 한국어 표현에 대응하기 어렵다는 한계가 있었다. Kiwi는 이러한 한계를 극복하기 위해 **머신러닝 기법(특히 딥러닝 기반의 신경망 언어 모델)**을 도입하여, 대량의 텍스트 데이터를 스스로 학습하고 형태소 분석 규칙을 자동화하는 데 집중했다. 이를 통해 정확성과 유연성을 동시에 확보하고, 현대 한국어의 복잡한 문맥과 비정형적인 표현을 더 잘 이해하고 처리하는 것을 목표로 했다.\n",
        "\n",
        "### 2. Kiwi의 주요 특징 (무엇이 다를까?)\n",
        "Kiwi는 다음과 같은 독특하고 강력한 특징들을 가지고 있다.\n",
        "\n",
        "* 머신러닝 기반 분석:\n",
        "기존처럼 사람이 일일이 사전을 만들고 규칙을 정하는 대신, 대규모 텍스트 데이터(코퍼스)를 학습하여 단어의 패턴과 형태소 분리 기준을 자동으로 익힌다. 이는 신조어, 복합어(예: '비대면수업', '핵꿀잼') 처리 능력을 향상시키고, 띄어쓰기 오류가 있는 문장도 유연하게 처리할 수 있도록 돕는다.\n",
        "* 서브워드(Subword) 개념 활용:\n",
        "단어를 단순히 쪼개는 것뿐만 아니라, 단어를 더 작은 의미 단위인 서브워드로 분리하여 분석한다. 이는 미등록 단어나 신조어에 대한 강점을 높이는 데 기여한다.\n",
        "* 상세한 토큰 정보 제공:\n",
        "단순히 ('단어', '품사') 튜플만 반환하는 것이 아니라, 각 형태소에 대한 Token 객체를 반환한다. 이 객체 안에는 형태소의 표면형(form), 품사(tag), 시작 위치(start), 길이(len) 등 더 많은 메타데이터가 포함되어 있어 심화 분석에 매우 유용하다.\n",
        "* 확장성 및 사용자 친화성:\n",
        "사용자 사전을 쉽게 추가하고, 분석 규칙을 커스터마이징할 수 있는 기능을 제공하여 특정 연구 목적에 맞게 분석기를 튜닝하기 좋다.\n",
        "파이썬으로 구현되어 있어 설치 및 사용이 비교적 간편하다."
      ],
      "metadata": {
        "id": "PbSua5SF1V-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiwi 형태소 분석기 설치 (kiwi-analyzer 대신 kiwipiepy 사용)\n",
        "# 이전에 설치했다면 'Requirement already satisfied' 메시지가 나옵니다.\n",
        "!pip install kiwipiepy\n",
        "\n",
        "# Kiwi 라이브러리 불러오기 및 객체 생성\n",
        "# kiwipiepy를 설치하면 'kiwi.kiwi'가 아니라 'kiwipiepy' 모듈에서 직접 불러옵니다.\n",
        "from kiwipiepy import Kiwi\n",
        "\n",
        "kiwi = Kiwi()\n",
        "\n",
        "print(\"✅ Kiwi 형태소 분석기 준비 완료!\")\n",
        "\n",
        "# Kiwi로 문장 분석하기 (이전 실습 코드 재활용)\n",
        "sentence_for_kiwi = \"요즘 넷플릭스 드라마 너무 재밌음 꿀잼! 비대면 수업 괜찮아?\"\n",
        "\n",
        "print(f\"\\n--- Kiwi 분석 결과 (현대어/복합어 문장) ---\")\n",
        "for token in kiwi.tokenize(sentence_for_kiwi):\n",
        "    print(f\"('{token.form}', '{token.tag}')\", end=\" \")\n",
        "print(\"\\n-------------------------------------------\")\n",
        "\n",
        "# Kiwi의 상세 정보 확인 (예시: '넷플릭스' 토큰 객체)\n",
        "try:\n",
        "    tokens = kiwi.tokenize(sentence_for_kiwi)\n",
        "    netflix_token = None\n",
        "    for t in tokens:\n",
        "        if t.form == '넷플릭스':\n",
        "            netflix_token = t\n",
        "            break\n",
        "\n",
        "    if netflix_token:\n",
        "        print(f\"\\n--- '넷플릭스' 토큰 객체 상세 정보 ---\")\n",
        "        print(f\"원형(form): '{netflix_token.form}'\")\n",
        "        print(f\"품사(tag): '{netflix_token.tag}'\")\n",
        "        print(f\"시작 위치(start): {netflix_token.start}\")\n",
        "        print(f\"길이(len): {netflix_token.len}\")\n",
        "        print(\"---------------------------------------\")\n",
        "    else:\n",
        "        print(\"\\n(예시 토큰 '넷플릭스'를 찾을 수 없습니다. 문장을 다시 확인해주세요.)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ 오류 발생: {e}\")\n",
        "    print(\"문장 분석 또는 토큰 접근에 문제가 있습니다. 코드나 문장을 다시 확인해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXDekW402HFC",
        "outputId": "e3177304-da00-4a02-ff9e-9b4e362a5c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kiwipiepy\n",
            "  Downloading kiwipiepy-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting kiwipiepy_model<0.22,>=0.21 (from kiwipiepy)\n",
            "  Downloading kiwipiepy_model-0.21.0.tar.gz (35.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kiwipiepy) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kiwipiepy) (4.67.1)\n",
            "Downloading kiwipiepy-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: kiwipiepy_model\n",
            "  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.21.0-py3-none-any.whl size=35593192 sha256=3adf46f8f71c8b82b63917ebd664e89b778c7b5416134813ed46d17a9329441a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/16/3d/95053ab5298f0f0f22ffea6de0200b6f24bffb73cab4c1a828\n",
            "Successfully built kiwipiepy_model\n",
            "Installing collected packages: kiwipiepy_model, kiwipiepy\n",
            "Successfully installed kiwipiepy-0.21.0 kiwipiepy_model-0.21.0\n",
            "✅ Kiwi 형태소 분석기 준비 완료!\n",
            "\n",
            "--- Kiwi 분석 결과 (현대어/복합어 문장) ---\n",
            "('요즘', 'MAG') ('넷플릭스', 'NNP') ('드라마', 'NNG') ('너무', 'MAG') ('재밌', 'VA') ('음', 'EF') ('꿀잼', 'NNG') ('!', 'SF') ('비', 'XPN') ('대면', 'NNG') ('수업', 'NNG') ('괜찮', 'VA') ('어', 'EF') ('?', 'SF') \n",
            "-------------------------------------------\n",
            "\n",
            "--- '넷플릭스' 토큰 객체 상세 정보 ---\n",
            "원형(form): '넷플릭스'\n",
            "품사(tag): 'NNP'\n",
            "시작 위치(start): 3\n",
            "길이(len): 4\n",
            "---------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kiwi 실습 결과 해석**\n",
        "\n",
        "Kiwi는 넷플릭스, 재밌음, 꿀잼, 비대면과 같은 현대적이고 복합적인 단어들을 비교적 잘 분리하고 품사를 태깅하는 것을 확인할 수 있다.\n",
        "가장 큰 차이점은 각 형태소(토큰)가 Token 객체로 반환된다는 점이다. 이 객체는 form (단어), tag (품사) 외에도 start (원문에서의 시작 위치), len (길이) 등 다양한 속성을 가지고 있다. 이런 상세 정보는 텍스트 마이닝에서 단어의 위치나 문맥적 정보를 활용하는 심층 분석에 매우 유용하게 쓰일 수 있다."
      ],
      "metadata": {
        "id": "JfBvJu8o2Vtm"
      }
    }
  ]
}
