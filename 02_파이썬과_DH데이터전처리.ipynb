{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlcUIHaeBt+gQWe0WqNmVI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-yiJung/DH-Buddhist-Analysis-Tutorial/blob/main/2_%ED%8C%8C%EC%9D%B4%EC%8D%AC%EA%B3%BC_DH%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 데이터 다루기: **데이터 가져오기**\n",
        "\n",
        "## 💡 텍스트 분석의 시작: 데이터를 어떻게 가져올까?\n",
        "디지털 인문학 연구에서 방대한 텍스트 데이터를 분석하려면, 먼저 그 데이터를 내 컴퓨터(또는 코랩 환경)로 가져와야 한다.\n",
        "\n",
        "* API 호출 (Application Programming Interface): 웹 서비스가 데이터를 '문'을 열어주는 방식으로, 코드를 통해 직접 데이터를 요청하고 받아온다.\n",
        "\n",
        "* GitHub 리포지토리에서 파일 가져오기: 연구자들이 코드와 데이터를 공유하는 GitHub에서 직접 파일을 다운로드하는 방식이다.\n",
        "\n",
        "* 로컬 파일 업로드 및 Google Drive 연동: 내 컴퓨터에 있는 텍스트 파일(XML, TXT, Excel 등)을 Google Drive에 올린 후, 코랩에서 그 파일을 불러와 사용한다."
      ],
      "metadata": {
        "id": "ziQx3JIKz6ZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. API 호출로 텍스트 데이터 가져오기 (위키백과 예시)"
      ],
      "metadata": {
        "id": "HBRUNMFv0hUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 가져오기\n",
        "import requests # 웹 요청을 보내고 응답을 받는 라이브러리\n",
        "import json     # JSON 형식의 데이터를 다루는 라이브러리\n",
        "\n",
        "print(\"✅ requests, json 라이브러리 준비 완료!\")"
      ],
      "metadata": {
        "id": "FEOXWzAc0lCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08002570-4316-4583-9ee9-efd824fbae2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ requests, json 라이브러리 준비 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위키백과 API 호출하여 '특정문서' 가져오기\n",
        "\n",
        "# 위키백과 API 기본 URL\n",
        "WIKIPEDIA_API_URL = \"https://ko.wikipedia.org/w/api.php\"\n",
        "\n",
        "# API 요청에 필요한 매개변수 설정\n",
        "# action=query: 정보를 요청하는 동작\n",
        "# format=json: 응답 형식을 JSON으로 요청\n",
        "# prop=extracts: 문서 내용(extract)을 요청\n",
        "# exlimit=1: 하나의 문서만 요청\n",
        "# titles=현진건: '현진건' 문서를 요청\n",
        "# explaintext=1: HTML 태그 없이 순수 텍스트만 요청\n",
        "# redirects=1: 리다이렉트(다른 문서로 연결)가 있으면 따라가도록 설정\n",
        "params = {\n",
        "    \"action\": \"query\",\n",
        "    \"format\": \"json\",\n",
        "    \"prop\": \"extracts\",\n",
        "    \"exlimit\": \"1\",\n",
        "    \"titles\": \"현진건\",\n",
        "    \"explaintext\": \"1\",\n",
        "    \"redirects\": \"1\"\n",
        "}\n",
        "\n",
        "print(f\"--- 위키백과 API 호출: '{params['titles']}' 문서 가져오기 시작 ---\\n\")\n",
        "\n",
        "# requests.get() 함수로 API에 요청을 보내고 응답을 받습니다.\n",
        "response = requests.get(WIKIPEDIA_API_URL, params=params)\n",
        "\n",
        "# 응답이 성공적인지 확인 (상태 코드 200은 성공을 의미)\n",
        "if response.status_code == 200:\n",
        "    # 응답 내용을 JSON 형식으로 파싱합니다.\n",
        "    data = response.json()\n",
        "\n",
        "    # JSON 데이터에서 문서 내용을 추출합니다.\n",
        "    # 위키백과 API 응답 구조를 알면 원하는 부분을 찾을 수 있어요.\n",
        "    pages = data['query']['pages']\n",
        "\n",
        "    # 페이지 ID를 가져옵니다 (페이지 ID는 매번 다를 수 있으므로 첫 번째 페이지를 가져옴)\n",
        "    page_id = list(pages.keys())[0]\n",
        "\n",
        "    # 최종적으로 문서 텍스트를 추출합니다.\n",
        "    hyun_jin_geon_wiki_text = pages[page_id]['extract']\n",
        "\n",
        "    print(\"✅ 데이터 가져오기 성공!\")\n",
        "    print(f\"\\n--- '현진건' 위키백과 문서 내용 (일부) ---\\n\")\n",
        "    # 내용이 너무 길 수 있으니 앞부분만 출력합니다.\n",
        "    print(hyun_jin_geon_wiki_text[:500] + \"...\\n\")\n",
        "    print(\"------------------------------------------\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ 데이터 가져오기 실패! 상태 코드: {response.status_code}\")"
      ],
      "metadata": {
        "id": "h4v5wDSw0ptP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c0663c-bf1a-401e-8ada-bfffe3274715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 위키백과 API 호출: '현진건' 문서 가져오기 시작 ---\n",
            "\n",
            "✅ 데이터 가져오기 성공!\n",
            "\n",
            "--- '현진건' 위키백과 문서 내용 (일부) ---\n",
            "\n",
            "현진건(玄鎭健, 1900년 9월 2일~1943년 4월 25일)은 대한제국과 일제 강점 시대 조선(朝鮮)의 작가(문학 평론가 겸 수필가)이자, 소설가 겸 언론인, 독립 운동가였으며, 「운수 좋은 날」, 「술 권하는 사회」 등 20편의 단편소설과 7편의 중·장편 소설을 남겼다.\n",
            "1943년 4월 25일, 일제강점기 경성부에서 장결핵으로 병사한, 그의 본관은 연주 현씨(延州 玄氏)이며, 호는 빙허(憑虛)이고, 일제 지배하의 민족의 수난적 운명에 대한 객관적인 현실 묘사를 지향한 사실주의의 선구자로 꼽힌다.\n",
            "\n",
            "\n",
            "== 가계 ==\n",
            "현진건의 집안인 연주 현씨는 역관(譯官) 등의 잡과(雜科) 출신을 많이 배출한 중인(中人) 집안에 해당한다. 현진건의 6대조로 왜역(倭譯) 즉 일본어 통역관이었던 태형(泰衡)부터 한역(漢譯) 즉 중국어 통역관이었던 5대조 상복(商福), 몽역(蒙譯) 즉 몽골어 통역관이었던 시석(時錫)에 이르기까지 모두 역관으로서 활약하였으며(각자의 처가도 또한 역관 집안이었다) 증조부 ...\n",
            "\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2. GitHub 리포지토리에서 텍스트 파일 가져오기 (고전 소설 예시)"
      ],
      "metadata": {
        "id": "5pt8PwfA0zyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후 3주차 실습에서"
      ],
      "metadata": {
        "id": "aWneo9abXgxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 로컬 파일 업로드 및 Google Drive 연동으로 텍스트 가져오기"
      ],
      "metadata": {
        "id": "I3CuYbIC09Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"--- Google Drive 마운트 시작 (인증 필요) ---\")\n",
        "drive.mount('/content/drive') # 이 코드를 실행하면 인증 절차를 거쳐야 합니다.\n",
        "print(\"\\n✅ Google Drive 마운트 완료!\")"
      ],
      "metadata": {
        "id": "s9QthkmL0_ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff446d73-686e-4777-d68b-7065fc70a063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Google Drive 마운트 시작 (인증 필요) ---\n",
            "Mounted at /content/drive\n",
            "\n",
            "✅ Google Drive 마운트 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TXT 파일 경로 (여러분의 파일 경로로 수정해주세요!)\n",
        "txt_file_path = '/content/dila_buddhist_figures_analysis (1).xlsx'\n",
        "\n",
        "print(f\"--- TXT 파일 불러오기: '{txt_file_path}' ---\\n\")\n",
        "\n",
        "try:\n",
        "    with open(txt_file_path, 'r', encoding='utf-8') as f: # 'r'은 읽기 모드, 'utf-8'은 인코딩 방식\n",
        "        loaded_txt_data = f.read() # 파일의 모든 내용을 읽어옵니다.\n",
        "\n",
        "    print(\"✅ TXT 파일 불러오기 성공!\")\n",
        "    print(f\"\\n--- 불러온 TXT 파일 내용 (일부) ---\\n\")\n",
        "    print(loaded_txt_data[:200] + \"...\\n\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ 오류: '{txt_file_path}' 파일을 찾을 수 없습니다. 경로가 정확한지 확인해주세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "t1G8GpSV1F87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaa2e6a-bca6-4fb9-9a5a-1de0b0f196f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TXT 파일 불러오기: '/content/dila_buddhist_figures_analysis (1).xlsx' ---\n",
            "\n",
            "❌ 오류 발생: 'utf-8' codec can't decode byte 0xed in position 10: invalid continuation byte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET # XML 파싱을 위한 라이브러리\n",
        "\n",
        "# XML 파일 경로 (여러분의 파일 경로로 수정해주세요!)\n",
        "xml_file_path = '/content/drive/MyDrive/Colab_DH_Practice/my_dh_metadata.xml'\n",
        "\n",
        "print(f\"--- XML 파일 불러오기: '{xml_file_path}' ---\\n\")\n",
        "\n",
        "try:\n",
        "    tree = ET.parse(xml_file_path) # XML 파일을 파싱하여 트리 구조로 만듭니다.\n",
        "    root = tree.getroot() # 트리의 가장 상위 요소(루트)를 가져옵니다.\n",
        "\n",
        "    print(\"✅ XML 파일 불러오기 성공!\")\n",
        "    print(\"\\n--- XML 파일에서 문서 메타데이터 추출 ---\")\n",
        "\n",
        "    # XML 구조를 순회하며 데이터를 추출합니다.\n",
        "    for doc in root.findall('document'): # 'document' 태그를 모두 찾습니다.\n",
        "        doc_id = doc.get('id') # 'document' 태그의 'id' 속성을 가져옵니다.\n",
        "        title = doc.find('title').text # 'title' 태그의 텍스트 내용을 가져옵니다.\n",
        "        author = doc.find('author').text # 'author' 태그의 텍스트 내용을 가져옵니다.\n",
        "        excerpt = doc.find('excerpt').text # 'excerpt' 태그의 텍스트 내용을 가져옵니다.\n",
        "\n",
        "        print(f\"\\n[문서 ID: {doc_id}]\")\n",
        "        print(f\"제목: {title}\")\n",
        "        print(f\"저자: {author}\")\n",
        "        print(f\"내용 발췌: {excerpt[:50]}...\") # 발췌 내용이 길 수 있으니 일부만 출력\n",
        "\n",
        "    print(\"\\n-------------------------------------------\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ 오류: '{xml_file_path}' 파일을 찾을 수 없습니다. 경로가 정확한지 확인해주세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "NQxY2jrO1KmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl # Excel 파일(.xlsx)을 읽기 위해 필요한 라이브러리 설치 (최초 1회)\n",
        "\n",
        "import pandas as pd # 데이터를 표(DataFrame) 형태로 다루는 강력한 라이브러리\n",
        "\n",
        "# Excel 파일 경로 (여러분의 파일 경로로 수정해주세요!)\n",
        "excel_file_path = '/content/drive/MyDrive/Colab_DH_Practice/my_research_data.xlsx'\n",
        "\n",
        "print(f\"--- Excel 파일 불러오기: '{excel_file_path}' ---\\n\")\n",
        "\n",
        "try:\n",
        "    # pd.read_excel() 함수로 Excel 파일을 불러옵니다.\n",
        "    df_research_data = pd.read_excel(excel_file_path)\n",
        "\n",
        "    print(\"✅ Excel 파일 불러오기 성공!\")\n",
        "    print(\"\\n--- 불러온 Excel 데이터 (상위 5개 행) ---\\n\")\n",
        "    print(df_research_data.head()) # 데이터의 상위 5개 행만 출력\n",
        "    print(\"\\n-------------------------------------------\")\n",
        "\n",
        "    print(\"\\n--- '저자' 컬럼의 데이터만 확인 ---\")\n",
        "    print(df_research_data['저자']) # '저자'라는 컬럼(열)의 데이터만 선택하여 출력\n",
        "    print(\"\\n----------------------------------\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ 오류: '{excel_file_path}' 파일을 찾을 수 없습니다. 경로가 정확한지 확인해주세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "F-r3kbaY1Nwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 데이터 다루기: **전처리 기초와 파이썬 실습 입문**"
      ],
      "metadata": {
        "id": "_NrZaA6nLMp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💡 텍스트 전처리(Text Preprocessing)\n",
        "\n",
        "텍스트 데이터는 우리가 생각하는 것보다 훨씬 '정돈되지 않은' 경우가 많다. 텍스트 분석을 시작하기 전에 이 데이터를 깨끗하게 만들고, 컴퓨터가 이해할 수 있는 형태로 바꿔주는 작업이 필요한데, 이것이 바로 **텍스트 전처리(Text Preprocessing)**이다.\n",
        "\n",
        "## 1. 왜 텍스트 전처리가 필요할까요?\n",
        "\n",
        "* 노이즈(Noise) 제거:\n",
        "우리가 사용하는 글에는 오탈자, 불필요한 특수문자(예: !?@#), 의미 없는 공백, 중복된 단어 등이 많다. 이런 '노이즈'들은 컴퓨터가 텍스트를 정확하게 이해하고 분석하는 것을 방해한다.\n",
        "** 예시: \"넘흐 좋다!!\" (오탈자+특수문자), \"텍스트 분석은 재미있다.\" (불필요한 공백)\n",
        "\n",
        "* 분석 효율성 증대:\n",
        "컴퓨터는 '책을 읽다', '책 읽기', '책을 읽고'가 모두 '책을 읽는 행위'와 관련되어 있다는 걸 바로 알지 못한다. 각각 다른 단어로 인식한다. 이런 단어들을 하나의 대표 형태로 만들어주면 분석 효율성이 훨씬 높아진다. 문장 속에서 정말 중요한 단어(핵심 키워드)만 골라내면, 컴퓨터가 훨씬 빠르게 핵심 내용을 파악할 수 있다.\n",
        "\n",
        "* 디지털 인문학에서 중요성: 역사적 사료나 문학 텍스트에는 필사 과정의 오류, 시대적 표현, 다양한 표기법 등 전통적인 연구에서도 중요한 '노이즈'가 많다. 정확한 전처리 없이는 텍스트 해석의 오류가 발생하거나, 미묘한 의미를 놓칠 수 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "SPA6d3PEsUAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 텍스트 전처리 단계에서 무엇을 할까? (주요 기법과 용어)\n",
        "\n",
        "### 데이터 파싱(Data Parsing):\n",
        "\n",
        "* 개념: XML, JSON, HTML처럼 특정 규칙을 가진 파일에서 우리가 원하는 텍스트 데이터만 '쏙쏙' 뽑아내는 과정.\n",
        "\n",
        "* 예시: 웹페이지에서 본문 내용만 가져오거나, 구조화된 문서에서 책 제목만 추출하는 것.\n",
        "\n",
        "* 디지털 인문학: 디지털 아카이브에서 제공하는 XML/JSON 형태의 사료나 문학 작품 파일에서 본문 텍스트를 효율적으로 추출할 때 사용한다.\n",
        "\n",
        "### 토큰화(Tokenization) & 형태소 분석(Morpheme Analysis):\n",
        "\n",
        "* 개념: 텍스트를 분석하기 위한 최소 의미 단위로 쪼개는 과정. 이 최소 단위를 **토큰(Token)**이라고 한다.\n",
        "\n",
        "* 왜 중요할까: 특히 한국어는 '은/는/이/가' 같은 조사가 단어에 붙고, 동사/형용사의 어미가 변하는 교착어라서 단순히 띄어쓰기로만 쪼개면 의미를 정확히 알기 어렵다.\n",
        "\n",
        "* 형태소: 의미를 가진 가장 작은 말의 단위 (예: '하늘이' = '하늘' + '이').\n",
        "\n",
        "### 형태소 분석: 텍스트를 이 형태소 단위로 쪼개는 과정.\n",
        "\n",
        "* 디지털 인문학: 한국 문학, 역사 기록 등을 분석할 때 단어의 정확한 원형과 의미를 파악하는 데 필수적.\n",
        "\n",
        "### 품사 태깅(Part-of-Speech Tagging, POS Tagging):\n",
        "\n",
        "* 개념: 쪼개진 형태소에 품사(Part-of-Speech) 이름표(예: 명사, 동사, 형용사)를 붙여주는 과정.\n",
        "\n",
        "* 예시: '나는' -> '나(명사)', '는(조사)'; '먹었다' -> '먹(동사)', '었(어미)', '다(어미)'.\n",
        "\n",
        "* 디지털 인문학: 품사 정보를 활용하면 '명사'만 골라 핵심 키워드를 찾거나, '동사'만으로 인물의 행동 패턴을 분석하는 등 정교한 분석이 가능하다.\n",
        "\n",
        "### 정규화(Normalization):\n",
        "\n",
        "* 개념: 텍스트 데이터의 형태를 일관되게 만드는 과정.\n",
        "\n",
        "* 예시:\n",
        "\n",
        "  (1) 대소문자 통일: 영어 텍스트의 'Text', 'text'를 모두 'text'로 통일.\n",
        "\n",
        "  (2) 오탈자 교정: '안녕학세요'를 '안녕하세요'로 수정.\n",
        "\n",
        "  (3) 불필요한 문자 제거: '텍스트!@#$'에서 특수문자 제거.\n",
        "\n",
        "  (4) 공백 제거: '텍스트 분석'에서 불필요한 공백을 하나로 줄이기.\n",
        "\n",
        "* 디지털 인문학: 고문헌의 다양한 이체자(異體字) 표기를 통일하거나, 시대별로 달라진 표현을 표준화하는 데 활용될 수 있어요.\n",
        "\n",
        "### 불용어(Stop Words) 처리:\n",
        "\n",
        "* 개념: 텍스트 분석에서 큰 의미가 없어 제거하는 단어들을 불용어라고한다. '은, 는, 이, 가, 그리고, 하다' 등 자주 나오지만 텍스트의 핵심 의미를 파악하는 데 방해가 되는 단어들이 대표적이다. 그러나 연구 주제에 따라 조사가 아닌 특정 단어가 불용어가 될 수 있다.\n",
        "\n",
        "* 디지털 인문학: 특정 단어의 빈도를 높이거나, 텍스트의 핵심 주제를 가리는 불필요한 단어를 제거하여 분석의 정확도를 높인다.\n",
        "\n",
        "### 표제어 추출(Lemmatization) vs. 어간 추출(Stemming):\n",
        "\n",
        "* 개념: 단어의 다양한 변화 형태(예: '뛰다', '뛰는', '뛰어서')에서 기본형이나 원형을 찾아내는 기법.\n",
        "\n",
        "* 표제어 추출 (Lemmatization): 단어의 **원형(기본 사전형)**을 찾는다. 품사를 고려하며, 실제로 존재하는 단어로 변환한다. (예: 'running' -> 'run', 'better' -> 'good')\n",
        "\n",
        "* 어간 추출 (Stemming): 단어의 접미사 등을 제거하여 의미론적인 핵심 부분(어간)을 추출한다. 사전에 없는 형태가 나올 수도 있다. (예: 'running' -> 'run', 'better' -> 'better' 또는 'bett')\n",
        "\n",
        "* 디지털 인문학 (한국어의 경우): 한국어는 어간과 어미가 결합하여 다양한 형태를 띠므로, 단순히 어간 추출보다는 **형태소 분석을 통한 표제어 추출(명사, 동사 원형 등)**이 훨씬 중요하고 정확하다."
      ],
      "metadata": {
        "id": "nW4pCMz7s5nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # 웹 요청을 보내고 응답을 받는 라이브러리\n",
        "import json     # JSON 형식의 데이터를 다루는 라이브러리\n",
        "\n",
        "print(\"✅ requests, json 라이브러리 준비 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ6nPAcfu6rd",
        "outputId": "5cf3d0a2-3edf-4dfc-d30c-895adb740b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ requests, json 라이브러리 준비 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위키문서 API 기본 URL\n",
        "WIKISOURCE_API_URL = \"https://ko.wikisource.org/w/api.php\"\n",
        "\n",
        "# API 요청에 필요한 매개변수 설정\n",
        "# action=query: 정보를 요청하는 동작\n",
        "# format=json: 응답 형식을 JSON으로 요청\n",
        "# prop=extracts: 문서 내용(extract)을 요청\n",
        "# exlimit=1: 하나의 문서만 요청\n",
        "# titles=부모은중경: '부모은중경' 문서를 요청\n",
        "# explaintext=1: HTML 태그나 위키 문법 없이 순수 텍스트만 요청\n",
        "# redirects=1: 리다이렉트(다른 문서로 연결)가 있으면 따라가도록 설정\n",
        "params = {\n",
        "    \"action\": \"query\",\n",
        "    \"format\": \"json\",\n",
        "    \"prop\": \"extracts\",\n",
        "    \"exlimit\": \"1\",\n",
        "    \"titles\": \"부모은중경\",\n",
        "    \"explaintext\": \"1\",\n",
        "    \"redirects\": \"1\"\n",
        "}\n",
        "\n",
        "print(f\"--- 위키문서 API 호출: '{params['titles']}' 문서 가져오기 시작 ---\\n\")\n",
        "\n",
        "# requests.get() 함수로 API에 요청을 보내고 응답을 받습니다.\n",
        "response = requests.get(WIKISOURCE_API_URL, params=params)\n",
        "\n",
        "# 응답이 성공적인지 확인 (HTTP 상태 코드 200은 성공을 의미)\n",
        "if response.status_code == 200:\n",
        "    # 응답 내용을 JSON 형식으로 파싱합니다.\n",
        "    data = response.json()\n",
        "\n",
        "    # JSON 데이터 구조를 탐색하여 문서 내용을 추출합니다.\n",
        "    # 위키백과/위키문서 API 응답은 'query' -> 'pages' 아래에 페이지 ID가 키로 있는 구조입니다.\n",
        "    pages = data['query']['pages']\n",
        "\n",
        "    # 페이지 ID를 가져옵니다 (페이지 ID는 매번 다를 수 있으므로 첫 번째 페이지를 가져옴)\n",
        "    page_id = list(pages.keys())[0]\n",
        "\n",
        "    # 최종적으로 문서 텍스트를 추출합니다.\n",
        "    text_bueonmo_eunjung_gyeong = pages[page_id]['extract']\n",
        "\n",
        "    print(\"✅ '부모은중경' 텍스트 가져오기 성공!\")\n",
        "    print(f\"\\n--- 가져온 '부모은중경' 텍스트 내용 (일부 미리보기) ---\\n\")\n",
        "    # 내용이 매우 길 수 있으니 앞부분 500자만 출력합니다.\n",
        "    print(text_bueonmo_eunjung_gyeong[:500] + \"...\\n\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ 데이터 가져오기 실패! 상태 코드: {response.status_code}\")\n",
        "    text_bueonmo_eunjung_gyeong = \"\" # 실패 시 빈 문자열로 초기화하여 다음 단계 오류 방지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNU1qMlY5LKI",
        "outputId": "2d26c4ca-790a-4f61-e00b-5c393106245b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 위키문서 API 호출: '부모은중경' 문서 가져오기 시작 ---\n",
            "\n",
            "✅ '부모은중경' 텍스트 가져오기 성공!\n",
            "\n",
            "--- 가져온 '부모은중경' 텍스트 내용 (일부 미리보기) ---\n",
            "\n",
            "\n",
            "== 서분 ==\n",
            "이와 같이 나는 들었다.\n",
            "어느 때 부처님께서는 사위국 왕사성의 기수급고독원에서 삼만팔천인의 대비구와 보살들과 함께 계시었다.\n",
            "\n",
            "\n",
            "== 정종분 ==\n",
            "\n",
            "\n",
            "=== 보은인연 ===\n",
            "그때 세존께서는 대중을 거느리고 남방으로 가시다가, 한 무더기의 뼈를 보시고는 오체투지의 예배를 올리셨다. 이에 아난과 대중이 부처님께 아뢰었다.\n",
            "\n",
            "세존이시여, 여래는 삼계의 큰 스승이요 사생의 자비로운 어버이시기에 수많은 사람들이 공경하고 귀의하옵니다. 그런데 어찌하여 이름모를 뼈무더기에 친히 절을 하시옵니까?\n",
            "부처님께서 아난에게 말씀하셔다.\n",
            "\n",
            "네가 비록 나의 으뜸가는 제자 중 한 사람이요 출가한 지도 오래 되었지만 아직 아는 것이 넓지 못하구나. 이 한무더기의 마른 뼈가 어쩌면 내 전생의 조상이거나 여러 대에 걸친 부모의 뼈일 수도 있기 때문에 내가 지금 예배한 것이니라.\n",
            "부처님께서 아난에게 말씀하셨다.\n",
            "\n",
            "이 한무더기의 마른 뼈를 둘로 나누어 보아라. 만일 남자의 뼈라면 희고 무거울 것이며,...\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. 위키문서 API 호출하여 '부모은중경' 문서 가져오기\n",
        "이제 위키문서에서 '부모은중경' 문서를 API로 가져와 봅시다."
      ],
      "metadata": {
        "id": "Co2-7j9n5oHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # 정규 표현식(Regular Expression)을 사용하기 위한 라이브러리\n",
        "\n",
        "# 여러 줄 바꿈을 하나의 공백으로, 여러 공백을 하나의 공백으로 줄이는 정규화\n",
        "cleaned_text = re.sub(r'\\n+', ' ', text_bueonmo_eunjung_gyeong) # 여러 줄 바꿈을 공백 하나로\n",
        "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip() # 여러 공백을 공백 하나로, 앞뒤 공백 제거\n",
        "\n",
        "print(f\"--- 클리닝된 '부모은중경' 텍스트 (일부) ---\\n\")\n",
        "print(cleaned_text[:500] + \"...\\n\")\n",
        "print(\"------------------------------------------------\")"
      ],
      "metadata": {
        "id": "VM7utwPR5Yn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b2ed9-4d79-41ac-e0c2-1ead0972f75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 클리닝된 '부모은중경' 텍스트 (일부) ---\n",
            "\n",
            "== 서분 == 이와 같이 나는 들었다. 어느 때 부처님께서는 사위국 왕사성의 기수급고독원에서 삼만팔천인의 대비구와 보살들과 함께 계시었다. == 정종분 == === 보은인연 === 그때 세존께서는 대중을 거느리고 남방으로 가시다가, 한 무더기의 뼈를 보시고는 오체투지의 예배를 올리셨다. 이에 아난과 대중이 부처님께 아뢰었다. 세존이시여, 여래는 삼계의 큰 스승이요 사생의 자비로운 어버이시기에 수많은 사람들이 공경하고 귀의하옵니다. 그런데 어찌하여 이름모를 뼈무더기에 친히 절을 하시옵니까? 부처님께서 아난에게 말씀하셔다. 네가 비록 나의 으뜸가는 제자 중 한 사람이요 출가한 지도 오래 되었지만 아직 아는 것이 넓지 못하구나. 이 한무더기의 마른 뼈가 어쩌면 내 전생의 조상이거나 여러 대에 걸친 부모의 뼈일 수도 있기 때문에 내가 지금 예배한 것이니라. 부처님께서 아난에게 말씀하셨다. 이 한무더기의 마른 뼈를 둘로 나누어 보아라. 만일 남자의 뼈라면 희고 무거울 것이며, 여자의 뼈라면...\n",
            "\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 텍스트 전처리: 불교 경전 '부모은중경' 다듬기\n",
        "가져온 '부모은중경' 텍스트는 긴 문자열 형태입니다. 이제 이 텍스트를 분석하기 좋게 다듬는 전처리(Preprocessing) 과정을 시작해 봅시다. 특히 불필요한 공백이나 줄 바꿈을 정리하고, 형태소 분석을 통해 단어를 추출할 거예요.\n",
        "\n",
        "2.1. 텍스트 클리닝 (기본 정규화)\n",
        "API에서 explaintext=1 옵션을 사용했기 때문에 대부분의 위키 문법은 제거되지만, 남은 불필요한 공백이나 줄 바꿈 문자 등을 제거하여 텍스트를 '정규화'하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "NuY5jCui5m6s"
      }
    }
  ]
}
